{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Relation Data EDA\n",
    "\n",
    "This notebook computes summary statistics and performs sanity checks on the relation data processing pipeline (raw_data -> relations database and sentences tagged with key terms)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Use device: cpu\n",
      "---\n",
      "Loading: tokenize\n",
      "With settings: \n",
      "{'model_path': '/Users/mattboggess/stanfordnlp_resources/en_ewt_models/en_ewt_tokenizer.pt', 'lang': 'en', 'shorthand': 'en_ewt', 'mode': 'predict'}\n",
      "---\n",
      "Loading: pos\n",
      "With settings: \n",
      "{'model_path': '/Users/mattboggess/stanfordnlp_resources/en_ewt_models/en_ewt_tagger.pt', 'pretrain_path': '/Users/mattboggess/stanfordnlp_resources/en_ewt_models/en_ewt.pretrain.pt', 'lang': 'en', 'shorthand': 'en_ewt', 'mode': 'predict'}\n",
      "---\n",
      "Loading: lemma\n",
      "With settings: \n",
      "{'model_path': '/Users/mattboggess/stanfordnlp_resources/en_ewt_models/en_ewt_lemmatizer.pt', 'lang': 'en', 'shorthand': 'en_ewt', 'mode': 'predict'}\n",
      "Building an attentional Seq2Seq model...\n",
      "Using a Bi-LSTM encoder\n",
      "Using soft attention for LSTM.\n",
      "Finetune all embeddings.\n",
      "[Running seq2seq lemmatizer with edit classifier]\n",
      "---\n",
      "Loading: depparse\n",
      "With settings: \n",
      "{'model_path': '/Users/mattboggess/stanfordnlp_resources/en_ewt_models/en_ewt_parser.pt', 'pretrain_path': '/Users/mattboggess/stanfordnlp_resources/en_ewt_models/en_ewt.pretrain.pt', 'lang': 'en', 'shorthand': 'en_ewt', 'mode': 'predict'}\n",
      "Done loading processors!\n",
      "---\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import pickle\n",
    "import json\n",
    "from collections import defaultdict\n",
    "import spacy\n",
    "import stanfordnlp\n",
    "import pandas as pd\n",
    "from spacy_stanfordnlp import StanfordNLPLanguage\n",
    "import warnings\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "from ipywidgets import interact\n",
    "\n",
    "# nlp preprocessing pipeline\n",
    "warnings.filterwarnings('ignore')\n",
    "snlp = stanfordnlp.Pipeline(lang=\"en\")\n",
    "nlp = StanfordNLPLanguage(snlp)\n",
    "\n",
    "# fix for importing utils\n",
    "module_path = os.path.abspath(os.path.join('../data_processing'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "from data_processing_utils import read_spacy_docs, tag_terms\n",
    "\n",
    "data_dir = '../data/relation_extraction'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What concepts actually match the text?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "bio_sentences = read_spacy_docs(\"../data/preprocessed_data/Biology_2e_sentences_spacy\", nlp)\n",
    "bio_sentences += read_spacy_docs(\"../data/preprocessed_data/Life_Biology_sentences_spacy\", nlp)\n",
    "kb_terms = read_spacy_docs(\"../data/preprocessed_data/Life_Biology_kb_key_terms_spacy\", nlp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tagging sentence 0/44162\n",
      "tagging sentence 500/44162\n",
      "tagging sentence 1000/44162\n",
      "tagging sentence 1500/44162\n",
      "tagging sentence 2000/44162\n",
      "tagging sentence 2500/44162\n",
      "tagging sentence 3000/44162\n",
      "tagging sentence 3500/44162\n",
      "tagging sentence 4000/44162\n",
      "tagging sentence 4500/44162\n",
      "tagging sentence 5000/44162\n",
      "tagging sentence 5500/44162\n",
      "tagging sentence 6000/44162\n",
      "tagging sentence 6500/44162\n",
      "tagging sentence 7000/44162\n",
      "tagging sentence 7500/44162\n",
      "tagging sentence 8000/44162\n",
      "tagging sentence 8500/44162\n",
      "tagging sentence 9000/44162\n",
      "tagging sentence 9500/44162\n",
      "tagging sentence 10000/44162\n",
      "tagging sentence 10500/44162\n",
      "tagging sentence 11000/44162\n",
      "tagging sentence 11500/44162\n",
      "tagging sentence 12000/44162\n",
      "tagging sentence 12500/44162\n",
      "tagging sentence 13000/44162\n",
      "tagging sentence 13500/44162\n",
      "tagging sentence 14000/44162\n",
      "tagging sentence 14500/44162\n",
      "tagging sentence 15000/44162\n",
      "tagging sentence 15500/44162\n",
      "tagging sentence 16000/44162\n",
      "tagging sentence 16500/44162\n",
      "tagging sentence 17000/44162\n",
      "tagging sentence 17500/44162\n",
      "tagging sentence 18000/44162\n",
      "tagging sentence 18500/44162\n",
      "tagging sentence 19000/44162\n",
      "tagging sentence 19500/44162\n",
      "tagging sentence 20000/44162\n",
      "tagging sentence 20500/44162\n",
      "tagging sentence 21000/44162\n",
      "tagging sentence 21500/44162\n",
      "tagging sentence 22000/44162\n",
      "tagging sentence 22500/44162\n",
      "tagging sentence 23000/44162\n",
      "tagging sentence 23500/44162\n",
      "tagging sentence 24000/44162\n",
      "tagging sentence 24500/44162\n",
      "tagging sentence 25000/44162\n",
      "tagging sentence 25500/44162\n",
      "tagging sentence 26000/44162\n",
      "tagging sentence 26500/44162\n",
      "tagging sentence 27000/44162\n",
      "tagging sentence 27500/44162\n",
      "tagging sentence 28000/44162\n",
      "tagging sentence 28500/44162\n",
      "tagging sentence 29000/44162\n",
      "tagging sentence 29500/44162\n",
      "tagging sentence 30000/44162\n",
      "tagging sentence 30500/44162\n",
      "tagging sentence 31000/44162\n",
      "tagging sentence 31500/44162\n",
      "tagging sentence 32000/44162\n",
      "tagging sentence 32500/44162\n",
      "tagging sentence 33000/44162\n",
      "tagging sentence 33500/44162\n",
      "tagging sentence 34000/44162\n",
      "tagging sentence 34500/44162\n",
      "tagging sentence 35000/44162\n",
      "tagging sentence 35500/44162\n",
      "tagging sentence 36000/44162\n",
      "tagging sentence 36500/44162\n",
      "tagging sentence 37000/44162\n",
      "tagging sentence 37500/44162\n",
      "tagging sentence 38000/44162\n",
      "tagging sentence 38500/44162\n",
      "tagging sentence 39000/44162\n",
      "tagging sentence 39500/44162\n",
      "tagging sentence 40000/44162\n",
      "tagging sentence 40500/44162\n",
      "tagging sentence 41000/44162\n",
      "tagging sentence 41500/44162\n",
      "tagging sentence 42000/44162\n",
      "tagging sentence 42500/44162\n",
      "tagging sentence 43000/44162\n",
      "tagging sentence 43500/44162\n",
      "tagging sentence 44000/44162\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "# count occurrences of all terms\n",
    "term_counts = Counter()\n",
    "for i, sentence in enumerate(bio_sentences):\n",
    "    if i % 500 == 0:\n",
    "        print(f\"tagging sentence {i}/{len(bio_sentences)}\")\n",
    "    term_info = tag_terms(sentence, kb_terms, nlp)[\"found_terms\"]\n",
    "    term_counts.update({t: len(term_info[t][\"indices\"]) for t in term_info})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3922/5686 bio kb concepts tagged in text\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../data/relation_extraction/diagnostics/not_tagged_concepts.xlsx'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-62e475b96819>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"concept\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"text\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconcept\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"text_representations\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_excel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"../data/relation_extraction/diagnostics/not_tagged_concepts.xlsx\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m//anaconda3/envs/tokn/lib/python3.7/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36mto_excel\u001b[0;34m(self, excel_writer, sheet_name, na_rep, float_format, columns, header, index, index_label, startrow, startcol, engine, merge_cells, encoding, inf_rep, verbose, freeze_panes)\u001b[0m\n\u001b[1;32m   2254\u001b[0m             \u001b[0mstartcol\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstartcol\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2255\u001b[0m             \u001b[0mfreeze_panes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfreeze_panes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2256\u001b[0;31m             \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2257\u001b[0m         )\n\u001b[1;32m   2258\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda3/envs/tokn/lib/python3.7/site-packages/pandas/io/formats/excel.py\u001b[0m in \u001b[0;36mwrite\u001b[0;34m(self, writer, sheet_name, startrow, startcol, freeze_panes, engine)\u001b[0m\n\u001b[1;32m    740\u001b[0m         )\n\u001b[1;32m    741\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mneed_save\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 742\u001b[0;31m             \u001b[0mwriter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m//anaconda3/envs/tokn/lib/python3.7/site-packages/pandas/io/excel/_openpyxl.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     42\u001b[0m         \u001b[0mSave\u001b[0m \u001b[0mworkbook\u001b[0m \u001b[0mto\u001b[0m \u001b[0mdisk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \"\"\"\n\u001b[0;32m---> 44\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbook\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mclassmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda3/envs/tokn/lib/python3.7/site-packages/openpyxl/workbook/workbook.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self, filename)\u001b[0m\n\u001b[1;32m    406\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite_only\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mworksheets\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    407\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_sheet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 408\u001b[0;31m         \u001b[0msave_workbook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    409\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    410\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda3/envs/tokn/lib/python3.7/site-packages/openpyxl/writer/excel.py\u001b[0m in \u001b[0;36msave_workbook\u001b[0;34m(workbook, filename)\u001b[0m\n\u001b[1;32m    289\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    290\u001b[0m     \"\"\"\n\u001b[0;32m--> 291\u001b[0;31m     \u001b[0marchive\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mZipFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'w'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mZIP_DEFLATED\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallowZip64\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    292\u001b[0m     \u001b[0mwriter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mExcelWriter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mworkbook\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marchive\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    293\u001b[0m     \u001b[0mwriter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda3/envs/tokn/lib/python3.7/zipfile.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, file, mode, compression, allowZip64, compresslevel)\u001b[0m\n\u001b[1;32m   1205\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1206\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1207\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilemode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1208\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1209\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mfilemode\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodeDict\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../data/relation_extraction/diagnostics/not_tagged_concepts.xlsx'"
     ]
    }
   ],
   "source": [
    "with open(\"../data/preprocessed_data/Life_Biology_kb_lexicon.json\", \"r\") as f:\n",
    "    lexicon = json.load(f)\n",
    "\n",
    "tagged_concepts = []\n",
    "non_tagged_concepts = []\n",
    "for concept in lexicon.keys():\n",
    "    if any([lemma in set(term_counts.keys()) for lemma in lexicon[concept][\"lemma_representations\"]]) or \\\n",
    "       any([text in set(term_counts.keys()) for text in lexicon[concept][\"text_representations\"]]):\n",
    "        tagged_concepts.append({concept: lexicon[concept]})\n",
    "    else:\n",
    "        non_tagged_concepts.append({concept: lexicon[concept]})\n",
    "print(f\"{len(tagged_concepts)}/{len(non_tagged_concepts) + len(tagged_concepts)} bio kb concepts tagged in text\")\n",
    "\n",
    "df = {\"concept\": [], \"text\": []}\n",
    "for concept in non_tagged_concepts:\n",
    "    c = list(concept.keys())[0]\n",
    "    df[\"concept\"].append(c)\n",
    "    df[\"text\"].append(concept[c][\"text_representations\"])\n",
    "pd.DataFrame(df).to_excel(\"../data/relation_extraction/diagnostics/not_tagged_concepts.xlsx\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Relations Database EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../data/relation_extraction/relations_db.json\", \"r\") as f:\n",
    "    rdb = json.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary Statistics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "long_df = {\"relation\": [], \"term_pair\": [], \"count_sentences\": [], \"found_sentence\": []}\n",
    "for relation in rdb:\n",
    "    for term_pair in rdb[relation]: \n",
    "        long_df[\"relation\"].append(relation)\n",
    "        long_df[\"term_pair\"].append(term_pair)\n",
    "        long_df[\"count_sentences\"].append(len(rdb[relation][term_pair][\"sentences\"]))\n",
    "        long_df[\"found_sentence\"].append(len(rdb[relation][term_pair][\"sentences\"]) > 0)\n",
    "long_df = pd.DataFrame(long_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>term_pair</th>\n",
       "      <th colspan=\"2\" halign=\"left\">count_sentences</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>sum</th>\n",
       "      <th>mean</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>relation</th>\n",
       "      <th>found_sentence</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td rowspan=\"2\" valign=\"top\">abuts</td>\n",
       "      <td>False</td>\n",
       "      <td>132</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>True</td>\n",
       "      <td>34</td>\n",
       "      <td>252</td>\n",
       "      <td>7.411765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td rowspan=\"2\" valign=\"top\">agent</td>\n",
       "      <td>False</td>\n",
       "      <td>1630</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>True</td>\n",
       "      <td>187</td>\n",
       "      <td>878</td>\n",
       "      <td>4.695187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>angle</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>surface-area</td>\n",
       "      <td>False</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>thickness</td>\n",
       "      <td>False</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>volume</td>\n",
       "      <td>False</td>\n",
       "      <td>108</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>wavelength</td>\n",
       "      <td>False</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>width</td>\n",
       "      <td>False</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>97 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                            term_pair count_sentences          \n",
       "                                count             sum      mean\n",
       "relation     found_sentence                                    \n",
       "abuts        False                132               0  0.000000\n",
       "             True                  34             252  7.411765\n",
       "agent        False               1630               0  0.000000\n",
       "             True                 187             878  4.695187\n",
       "angle        False                  1               0  0.000000\n",
       "...                               ...             ...       ...\n",
       "surface-area False                  6               0  0.000000\n",
       "thickness    False                 19               0  0.000000\n",
       "volume       False                108               0  0.000000\n",
       "wavelength   False                 18               0  0.000000\n",
       "width        False                  7               0  0.000000\n",
       "\n",
       "[97 rows x 3 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary_df = long_df.groupby([\"relation\", \"found_sentence\"]).agg({\"term_pair\": \"count\",\n",
    "                                                                  \"count_sentences\": [\"sum\", \"mean\"]})\n",
    "summary_df.to_csv(\"../data/relation_extraction/summary/relation_counts_summary.csv\", index=False)\n",
    "summary_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentence Count Distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "95881cff3a734d4996bfdaf62cb661b2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Dropdown(description='relation', options=('no-relation', 'subclass-of', 'has-part', 'pos…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from ipywidgets import interact\n",
    "\n",
    "def plot_sentence_counts(relation):\n",
    "    \n",
    "    df = long_df.query(f\"count_sentences > 0 & relation == '{relation}'\")\n",
    "    df = df.query(\"count_sentences < 30\")\n",
    "    plt.hist(df.count_sentences, bins=30)\n",
    "    plt.show()\n",
    "    \n",
    "interact(plot_sentence_counts, relation=list(rdb.keys()));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi-Label Term Pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2593 term pairs that have multiple relations\n"
     ]
    }
   ],
   "source": [
    "term_relation_mapping = {}\n",
    "for relation in rdb:\n",
    "    if relation == \"no-relation\":\n",
    "        continue\n",
    "    for tp in rdb[relation]:\n",
    "        cp = rdb[relation][tp][\"concept_pair\"]\n",
    "        pair = \", \".join([tp, cp])\n",
    "        if pair in term_relation_mapping:\n",
    "            term_relation_mapping[pair].append(relation)\n",
    "        else:\n",
    "            term_relation_mapping[pair] = [relation]\n",
    "multi_label = {k:r for k, r in term_relation_mapping.items() if len(r) > 1}\n",
    "print(f\"Found {len(multi_label)} term pairs that have multiple relations\")\n",
    "with open(f\"../data/relation_extraction/summary/multi_label_term_pairs.json\", \"w\") as f:\n",
    "    json.dump(multi_label, f, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sanity Check Relation Extraction \n",
    "\n",
    "- How many word-pairs match the text on regex, but we don't match in the pipeline?\n",
    "- How many word-pairs don't match sentences? Do these seem reasonable?\n",
    "- Word-pairs with too many matches?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "bio_sentences = read_spacy_docs(\"../data/preprocessed_data/Biology_2e_sentences_spacy\", nlp)\n",
    "bio_sentences += read_spacy_docs(\"../data/preprocessed_data/Life_Biology_sentences_spacy\", nlp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no-relation\n",
      "subclass-of\n",
      "Processing term pair 0/19179\n",
      "Processing term pair 100/19179\n",
      "Processing term pair 200/19179\n",
      "Processing term pair 300/19179\n",
      "Processing term pair 400/19179\n",
      "Processing term pair 500/19179\n",
      "Processing term pair 600/19179\n",
      "Processing term pair 700/19179\n",
      "Processing term pair 800/19179\n",
      "Processing term pair 900/19179\n",
      "Processing term pair 1000/19179\n",
      "Processing term pair 1100/19179\n",
      "Processing term pair 1200/19179\n",
      "Processing term pair 1300/19179\n",
      "Processing term pair 1400/19179\n",
      "Processing term pair 1500/19179\n",
      "Processing term pair 1600/19179\n",
      "Processing term pair 1700/19179\n",
      "Processing term pair 1800/19179\n",
      "Processing term pair 1900/19179\n",
      "Processing term pair 2000/19179\n",
      "Processing term pair 2100/19179\n",
      "Processing term pair 2200/19179\n",
      "Processing term pair 2300/19179\n",
      "Processing term pair 2400/19179\n",
      "Processing term pair 2500/19179\n",
      "Processing term pair 2600/19179\n",
      "Processing term pair 2700/19179\n",
      "Processing term pair 2800/19179\n",
      "Processing term pair 2900/19179\n",
      "Processing term pair 3000/19179\n",
      "Processing term pair 3100/19179\n",
      "Processing term pair 3200/19179\n",
      "Processing term pair 3300/19179\n",
      "Processing term pair 3400/19179\n",
      "Processing term pair 3500/19179\n",
      "Processing term pair 3600/19179\n",
      "Processing term pair 3700/19179\n",
      "Processing term pair 3800/19179\n",
      "Processing term pair 3900/19179\n",
      "Processing term pair 4000/19179\n",
      "Processing term pair 4100/19179\n",
      "Processing term pair 4200/19179\n",
      "Processing term pair 4300/19179\n",
      "Processing term pair 4400/19179\n",
      "Processing term pair 4500/19179\n",
      "Processing term pair 4600/19179\n",
      "Processing term pair 4700/19179\n",
      "Processing term pair 4800/19179\n",
      "Processing term pair 4900/19179\n",
      "Processing term pair 5000/19179\n",
      "Processing term pair 5100/19179\n",
      "Processing term pair 5200/19179\n",
      "Processing term pair 5300/19179\n",
      "Processing term pair 5400/19179\n",
      "Processing term pair 5500/19179\n",
      "Processing term pair 5600/19179\n",
      "Processing term pair 5700/19179\n",
      "Processing term pair 5800/19179\n",
      "Processing term pair 5900/19179\n",
      "Processing term pair 6000/19179\n",
      "Processing term pair 6100/19179\n",
      "Processing term pair 6200/19179\n",
      "Processing term pair 6300/19179\n",
      "Processing term pair 6400/19179\n",
      "Processing term pair 6500/19179\n",
      "Processing term pair 6600/19179\n",
      "Processing term pair 6700/19179\n",
      "Processing term pair 6800/19179\n",
      "Processing term pair 6900/19179\n",
      "Processing term pair 7000/19179\n",
      "Processing term pair 7100/19179\n",
      "Processing term pair 7200/19179\n",
      "Processing term pair 7300/19179\n",
      "Processing term pair 7400/19179\n",
      "Processing term pair 7500/19179\n",
      "Processing term pair 7600/19179\n",
      "Processing term pair 7700/19179\n",
      "Processing term pair 7800/19179\n",
      "Processing term pair 7900/19179\n",
      "Processing term pair 8000/19179\n",
      "Processing term pair 8100/19179\n",
      "Processing term pair 8200/19179\n",
      "Processing term pair 8300/19179\n",
      "Processing term pair 8400/19179\n",
      "Processing term pair 8500/19179\n",
      "Processing term pair 8600/19179\n",
      "Processing term pair 8700/19179\n",
      "Processing term pair 8800/19179\n",
      "Processing term pair 8900/19179\n",
      "Processing term pair 9000/19179\n",
      "Processing term pair 9100/19179\n",
      "Processing term pair 9200/19179\n",
      "Processing term pair 9300/19179\n",
      "Processing term pair 9400/19179\n",
      "Processing term pair 9500/19179\n",
      "Processing term pair 9600/19179\n",
      "Processing term pair 9700/19179\n",
      "Processing term pair 9800/19179\n",
      "Processing term pair 9900/19179\n",
      "Processing term pair 10000/19179\n",
      "Processing term pair 10100/19179\n",
      "Processing term pair 10200/19179\n",
      "Processing term pair 10300/19179\n",
      "Processing term pair 10400/19179\n",
      "Processing term pair 10500/19179\n",
      "Processing term pair 10600/19179\n",
      "Processing term pair 10700/19179\n",
      "Processing term pair 10800/19179\n",
      "Processing term pair 10900/19179\n",
      "Processing term pair 11000/19179\n",
      "Processing term pair 11100/19179\n",
      "Processing term pair 11200/19179\n",
      "Processing term pair 11300/19179\n",
      "Processing term pair 11400/19179\n",
      "Processing term pair 11500/19179\n",
      "Processing term pair 11600/19179\n",
      "Processing term pair 11700/19179\n",
      "Processing term pair 11800/19179\n",
      "Processing term pair 11900/19179\n",
      "Processing term pair 12000/19179\n",
      "Processing term pair 12100/19179\n",
      "Processing term pair 12200/19179\n",
      "Processing term pair 12300/19179\n",
      "Processing term pair 12400/19179\n",
      "Processing term pair 12500/19179\n",
      "Processing term pair 12600/19179\n",
      "Processing term pair 12700/19179\n",
      "Processing term pair 12800/19179\n",
      "Processing term pair 12900/19179\n",
      "Processing term pair 13000/19179\n",
      "Processing term pair 13100/19179\n",
      "Processing term pair 13200/19179\n",
      "Processing term pair 13300/19179\n",
      "Processing term pair 13400/19179\n",
      "Processing term pair 13500/19179\n",
      "Processing term pair 13600/19179\n",
      "Processing term pair 13700/19179\n",
      "Processing term pair 13800/19179\n",
      "Processing term pair 13900/19179\n",
      "Processing term pair 14000/19179\n",
      "Processing term pair 14100/19179\n",
      "Processing term pair 14200/19179\n",
      "Processing term pair 14300/19179\n",
      "Processing term pair 14400/19179\n",
      "Processing term pair 14500/19179\n",
      "Processing term pair 14600/19179\n",
      "Processing term pair 14700/19179\n",
      "Processing term pair 14800/19179\n",
      "Processing term pair 14900/19179\n",
      "Processing term pair 15000/19179\n",
      "Processing term pair 15100/19179\n",
      "Processing term pair 15200/19179\n",
      "Processing term pair 15300/19179\n",
      "Processing term pair 15400/19179\n",
      "Processing term pair 15500/19179\n",
      "Processing term pair 15600/19179\n",
      "Processing term pair 15700/19179\n",
      "Processing term pair 15800/19179\n",
      "Processing term pair 15900/19179\n",
      "Processing term pair 16000/19179\n",
      "Processing term pair 16100/19179\n",
      "Processing term pair 16200/19179\n",
      "Processing term pair 16300/19179\n",
      "Processing term pair 16400/19179\n",
      "Processing term pair 16500/19179\n",
      "Processing term pair 16600/19179\n",
      "Processing term pair 16700/19179\n",
      "Processing term pair 16800/19179\n",
      "Processing term pair 16900/19179\n",
      "Processing term pair 17000/19179\n",
      "Processing term pair 17100/19179\n",
      "Processing term pair 17200/19179\n",
      "Processing term pair 17300/19179\n",
      "Processing term pair 17400/19179\n",
      "Processing term pair 17500/19179\n",
      "Processing term pair 17600/19179\n",
      "Processing term pair 17700/19179\n",
      "Processing term pair 17800/19179\n",
      "Processing term pair 17900/19179\n",
      "Processing term pair 18000/19179\n",
      "Processing term pair 18100/19179\n",
      "Processing term pair 18200/19179\n",
      "Processing term pair 18300/19179\n",
      "Processing term pair 18400/19179\n",
      "Processing term pair 18500/19179\n",
      "Processing term pair 18600/19179\n",
      "Processing term pair 18700/19179\n",
      "Processing term pair 18800/19179\n",
      "Processing term pair 18900/19179\n",
      "Processing term pair 19000/19179\n",
      "Processing term pair 19100/19179\n",
      "has-part\n",
      "Processing term pair 0/6583\n",
      "Processing term pair 100/6583\n",
      "Processing term pair 200/6583\n",
      "Processing term pair 300/6583\n",
      "Processing term pair 400/6583\n",
      "Processing term pair 500/6583\n",
      "Processing term pair 600/6583\n",
      "Processing term pair 700/6583\n",
      "Processing term pair 800/6583\n",
      "Processing term pair 900/6583\n",
      "Processing term pair 1000/6583\n",
      "Processing term pair 1100/6583\n",
      "Processing term pair 1200/6583\n",
      "Processing term pair 1300/6583\n",
      "Processing term pair 1400/6583\n",
      "Processing term pair 1500/6583\n",
      "Processing term pair 1600/6583\n",
      "Processing term pair 1700/6583\n",
      "Processing term pair 1800/6583\n",
      "Processing term pair 1900/6583\n",
      "Processing term pair 2000/6583\n",
      "Processing term pair 2100/6583\n",
      "Processing term pair 2200/6583\n",
      "Processing term pair 2300/6583\n",
      "Processing term pair 2400/6583\n",
      "Processing term pair 2500/6583\n",
      "Processing term pair 2600/6583\n",
      "Processing term pair 2700/6583\n",
      "Processing term pair 2800/6583\n",
      "Processing term pair 2900/6583\n",
      "Processing term pair 3000/6583\n",
      "Processing term pair 3100/6583\n",
      "Processing term pair 3200/6583\n",
      "Processing term pair 3300/6583\n",
      "Processing term pair 3400/6583\n",
      "Processing term pair 3500/6583\n",
      "Processing term pair 3600/6583\n",
      "Processing term pair 3700/6583\n",
      "Processing term pair 3800/6583\n",
      "Processing term pair 3900/6583\n",
      "Processing term pair 4000/6583\n",
      "Processing term pair 4100/6583\n",
      "Processing term pair 4200/6583\n",
      "Processing term pair 4300/6583\n",
      "Processing term pair 4400/6583\n",
      "Processing term pair 4500/6583\n",
      "Processing term pair 4600/6583\n",
      "Processing term pair 4700/6583\n",
      "Processing term pair 4800/6583\n",
      "Processing term pair 4900/6583\n",
      "Processing term pair 5000/6583\n",
      "Processing term pair 5100/6583\n",
      "Processing term pair 5200/6583\n",
      "Processing term pair 5300/6583\n",
      "Processing term pair 5400/6583\n",
      "Processing term pair 5500/6583\n",
      "Processing term pair 5600/6583\n",
      "Processing term pair 5700/6583\n",
      "Processing term pair 5800/6583\n",
      "Processing term pair 5900/6583\n",
      "Processing term pair 6000/6583\n",
      "Processing term pair 6100/6583\n",
      "Processing term pair 6200/6583\n",
      "Processing term pair 6300/6583\n",
      "Processing term pair 6400/6583\n",
      "Processing term pair 6500/6583\n",
      "possesses\n",
      "Processing term pair 0/1897\n",
      "Processing term pair 100/1897\n",
      "Processing term pair 200/1897\n",
      "Processing term pair 300/1897\n",
      "Processing term pair 400/1897\n",
      "Processing term pair 500/1897\n",
      "Processing term pair 600/1897\n",
      "Processing term pair 700/1897\n",
      "Processing term pair 800/1897\n",
      "Processing term pair 900/1897\n",
      "Processing term pair 1000/1897\n",
      "Processing term pair 1100/1897\n",
      "Processing term pair 1200/1897\n",
      "Processing term pair 1300/1897\n",
      "Processing term pair 1400/1897\n",
      "Processing term pair 1500/1897\n",
      "Processing term pair 1600/1897\n",
      "Processing term pair 1700/1897\n",
      "Processing term pair 1800/1897\n",
      "has-region\n",
      "Processing term pair 0/3067\n",
      "Processing term pair 100/3067\n",
      "Processing term pair 200/3067\n",
      "Processing term pair 300/3067\n",
      "Processing term pair 400/3067\n",
      "Processing term pair 500/3067\n",
      "Processing term pair 600/3067\n",
      "Processing term pair 700/3067\n",
      "Processing term pair 800/3067\n",
      "Processing term pair 900/3067\n",
      "Processing term pair 1000/3067\n",
      "Processing term pair 1100/3067\n",
      "Processing term pair 1200/3067\n",
      "Processing term pair 1300/3067\n",
      "Processing term pair 1400/3067\n",
      "Processing term pair 1500/3067\n",
      "Processing term pair 1600/3067\n",
      "Processing term pair 1700/3067\n",
      "Processing term pair 1800/3067\n",
      "Processing term pair 1900/3067\n",
      "Processing term pair 2000/3067\n",
      "Processing term pair 2100/3067\n",
      "Processing term pair 2200/3067\n",
      "Processing term pair 2300/3067\n",
      "Processing term pair 2400/3067\n",
      "Processing term pair 2500/3067\n",
      "Processing term pair 2600/3067\n",
      "Processing term pair 2700/3067\n",
      "Processing term pair 2800/3067\n",
      "Processing term pair 2900/3067\n",
      "Processing term pair 3000/3067\n",
      "is-inside\n",
      "Processing term pair 0/1078\n",
      "Processing term pair 100/1078\n",
      "Processing term pair 200/1078\n",
      "Processing term pair 300/1078\n",
      "Processing term pair 400/1078\n",
      "Processing term pair 500/1078\n",
      "Processing term pair 600/1078\n",
      "Processing term pair 700/1078\n",
      "Processing term pair 800/1078\n",
      "Processing term pair 900/1078\n",
      "Processing term pair 1000/1078\n",
      "encloses\n",
      "Processing term pair 0/1050\n",
      "Processing term pair 100/1050\n",
      "Processing term pair 200/1050\n",
      "Processing term pair 300/1050\n",
      "Processing term pair 400/1050\n",
      "Processing term pair 500/1050\n",
      "Processing term pair 600/1050\n",
      "Processing term pair 700/1050\n",
      "Processing term pair 800/1050\n",
      "Processing term pair 900/1050\n",
      "Processing term pair 1000/1050\n",
      "is-below\n",
      "Processing term pair 0/25\n",
      "is-at\n",
      "Processing term pair 0/304\n",
      "Processing term pair 100/304\n",
      "Processing term pair 200/304\n",
      "Processing term pair 300/304\n",
      "structural-complexity\n",
      "Processing term pair 0/297\n",
      "Processing term pair 100/297\n",
      "Processing term pair 200/297\n",
      "size\n",
      "Processing term pair 0/427\n",
      "Processing term pair 100/427\n",
      "Processing term pair 200/427\n",
      "Processing term pair 300/427\n",
      "Processing term pair 400/427\n",
      "is-between\n",
      "Processing term pair 0/467\n",
      "Processing term pair 100/467\n",
      "Processing term pair 200/467\n",
      "Processing term pair 300/467\n",
      "Processing term pair 400/467\n",
      "does-not-enclose\n",
      "Processing term pair 0/217\n",
      "Processing term pair 100/217\n",
      "Processing term pair 200/217\n",
      "is-oriented-toward\n",
      "Processing term pair 0/10\n",
      "is-facing\n",
      "Processing term pair 0/8\n",
      "element\n",
      "Processing term pair 0/535\n",
      "Processing term pair 100/535\n",
      "Processing term pair 200/535\n",
      "Processing term pair 300/535\n",
      "Processing term pair 400/535\n",
      "Processing term pair 500/535\n",
      "abuts\n",
      "Processing term pair 0/166\n",
      "Processing term pair 100/166\n",
      "is-outside\n",
      "Processing term pair 0/195\n",
      "Processing term pair 100/195\n",
      "volume\n",
      "Processing term pair 0/108\n",
      "Processing term pair 100/108\n",
      "mass\n",
      "Processing term pair 0/14\n",
      "is-across\n",
      "Processing term pair 0/101\n",
      "Processing term pair 100/101\n",
      "shape\n",
      "Processing term pair 0/188\n",
      "Processing term pair 100/188\n",
      "diameter\n",
      "Processing term pair 0/29\n",
      "specific-surface-area\n",
      "Processing term pair 0/10\n",
      "is-near\n",
      "Processing term pair 0/68\n",
      "is-above\n",
      "Processing term pair 0/25\n",
      "atomic-weight\n",
      "Processing term pair 0/152\n",
      "Processing term pair 100/152\n",
      "length\n",
      "Processing term pair 0/100\n",
      "is-opposite\n",
      "Processing term pair 0/12\n",
      "is-along\n",
      "Processing term pair 0/67\n",
      "height\n",
      "Processing term pair 0/11\n",
      "depth\n",
      "Processing term pair 0/3\n",
      "is-on\n",
      "Processing term pair 0/10\n",
      "is-parallel-to\n",
      "Processing term pair 0/2\n",
      "wavelength\n",
      "Processing term pair 0/18\n",
      "has-ion\n",
      "Processing term pair 0/14\n",
      "thickness\n",
      "Processing term pair 0/19\n",
      "surface-area\n",
      "Processing term pair 0/6\n",
      "is-beside\n",
      "Processing term pair 0/8\n",
      "angle\n",
      "Processing term pair 0/1\n",
      "has-on-it\n",
      "Processing term pair 0/10\n",
      "is-over\n",
      "Processing term pair 0/2\n",
      "area\n",
      "Processing term pair 0/6\n",
      "width\n",
      "Processing term pair 0/7\n",
      "is-under\n",
      "Processing term pair 0/2\n",
      "is-behind\n",
      "Processing term pair 0/1\n",
      "base\n",
      "Processing term pair 0/2421\n",
      "Processing term pair 100/2421\n",
      "Processing term pair 200/2421\n",
      "Processing term pair 300/2421\n",
      "Processing term pair 400/2421\n",
      "Processing term pair 500/2421\n",
      "Processing term pair 600/2421\n",
      "Processing term pair 700/2421\n",
      "Processing term pair 800/2421\n",
      "Processing term pair 900/2421\n",
      "Processing term pair 1000/2421\n",
      "Processing term pair 1100/2421\n",
      "Processing term pair 1200/2421\n",
      "Processing term pair 1300/2421\n",
      "Processing term pair 1400/2421\n",
      "Processing term pair 1500/2421\n",
      "Processing term pair 1600/2421\n",
      "Processing term pair 1700/2421\n",
      "Processing term pair 1800/2421\n",
      "Processing term pair 1900/2421\n",
      "Processing term pair 2000/2421\n",
      "Processing term pair 2100/2421\n",
      "Processing term pair 2200/2421\n",
      "Processing term pair 2300/2421\n",
      "Processing term pair 2400/2421\n",
      "result\n",
      "Processing term pair 0/3873\n",
      "Processing term pair 100/3873\n",
      "Processing term pair 200/3873\n",
      "Processing term pair 300/3873\n",
      "Processing term pair 400/3873\n",
      "Processing term pair 500/3873\n",
      "Processing term pair 600/3873\n",
      "Processing term pair 700/3873\n",
      "Processing term pair 800/3873\n",
      "Processing term pair 900/3873\n",
      "Processing term pair 1000/3873\n",
      "Processing term pair 1100/3873\n",
      "Processing term pair 1200/3873\n",
      "Processing term pair 1300/3873\n",
      "Processing term pair 1400/3873\n",
      "Processing term pair 1500/3873\n",
      "Processing term pair 1600/3873\n",
      "Processing term pair 1700/3873\n",
      "Processing term pair 1800/3873\n",
      "Processing term pair 1900/3873\n",
      "Processing term pair 2000/3873\n",
      "Processing term pair 2100/3873\n",
      "Processing term pair 2200/3873\n",
      "Processing term pair 2300/3873\n",
      "Processing term pair 2400/3873\n",
      "Processing term pair 2500/3873\n",
      "Processing term pair 2600/3873\n",
      "Processing term pair 2700/3873\n",
      "Processing term pair 2800/3873\n",
      "Processing term pair 2900/3873\n",
      "Processing term pair 3000/3873\n",
      "Processing term pair 3100/3873\n",
      "Processing term pair 3200/3873\n",
      "Processing term pair 3300/3873\n",
      "Processing term pair 3400/3873\n",
      "Processing term pair 3500/3873\n",
      "Processing term pair 3600/3873\n",
      "Processing term pair 3700/3873\n",
      "Processing term pair 3800/3873\n",
      "next-event\n",
      "Processing term pair 0/929\n",
      "Processing term pair 100/929\n",
      "Processing term pair 200/929\n",
      "Processing term pair 300/929\n",
      "Processing term pair 400/929\n",
      "Processing term pair 500/929\n",
      "Processing term pair 600/929\n",
      "Processing term pair 700/929\n",
      "Processing term pair 800/929\n",
      "Processing term pair 900/929\n",
      "object\n",
      "Processing term pair 0/3050\n",
      "Processing term pair 100/3050\n",
      "Processing term pair 200/3050\n",
      "Processing term pair 300/3050\n",
      "Processing term pair 400/3050\n",
      "Processing term pair 500/3050\n",
      "Processing term pair 600/3050\n",
      "Processing term pair 700/3050\n",
      "Processing term pair 800/3050\n",
      "Processing term pair 900/3050\n",
      "Processing term pair 1000/3050\n",
      "Processing term pair 1100/3050\n",
      "Processing term pair 1200/3050\n",
      "Processing term pair 1300/3050\n",
      "Processing term pair 1400/3050\n",
      "Processing term pair 1500/3050\n",
      "Processing term pair 1600/3050\n",
      "Processing term pair 1700/3050\n",
      "Processing term pair 1800/3050\n",
      "Processing term pair 1900/3050\n",
      "Processing term pair 2000/3050\n",
      "Processing term pair 2100/3050\n",
      "Processing term pair 2200/3050\n",
      "Processing term pair 2300/3050\n",
      "Processing term pair 2400/3050\n",
      "Processing term pair 2500/3050\n",
      "Processing term pair 2600/3050\n",
      "Processing term pair 2700/3050\n",
      "Processing term pair 2800/3050\n",
      "Processing term pair 2900/3050\n",
      "Processing term pair 3000/3050\n",
      "agent\n",
      "Processing term pair 0/1817\n",
      "Processing term pair 100/1817\n",
      "Processing term pair 200/1817\n",
      "Processing term pair 300/1817\n",
      "Processing term pair 400/1817\n",
      "Processing term pair 500/1817\n",
      "Processing term pair 600/1817\n",
      "Processing term pair 700/1817\n",
      "Processing term pair 800/1817\n",
      "Processing term pair 900/1817\n",
      "Processing term pair 1000/1817\n",
      "Processing term pair 1100/1817\n",
      "Processing term pair 1200/1817\n",
      "Processing term pair 1300/1817\n",
      "Processing term pair 1400/1817\n",
      "Processing term pair 1500/1817\n",
      "Processing term pair 1600/1817\n",
      "Processing term pair 1700/1817\n",
      "Processing term pair 1800/1817\n",
      "subevent\n",
      "Processing term pair 0/3008\n",
      "Processing term pair 100/3008\n",
      "Processing term pair 200/3008\n",
      "Processing term pair 300/3008\n",
      "Processing term pair 400/3008\n",
      "Processing term pair 500/3008\n",
      "Processing term pair 600/3008\n",
      "Processing term pair 700/3008\n",
      "Processing term pair 800/3008\n",
      "Processing term pair 900/3008\n",
      "Processing term pair 1000/3008\n",
      "Processing term pair 1100/3008\n",
      "Processing term pair 1200/3008\n",
      "Processing term pair 1300/3008\n",
      "Processing term pair 1400/3008\n",
      "Processing term pair 1500/3008\n",
      "Processing term pair 1600/3008\n",
      "Processing term pair 1700/3008\n",
      "Processing term pair 1800/3008\n",
      "Processing term pair 1900/3008\n",
      "Processing term pair 2000/3008\n",
      "Processing term pair 2100/3008\n",
      "Processing term pair 2200/3008\n",
      "Processing term pair 2300/3008\n",
      "Processing term pair 2400/3008\n",
      "Processing term pair 2500/3008\n",
      "Processing term pair 2600/3008\n",
      "Processing term pair 2700/3008\n",
      "Processing term pair 2800/3008\n",
      "Processing term pair 2900/3008\n",
      "Processing term pair 3000/3008\n",
      "instrument\n",
      "Processing term pair 0/339\n",
      "Processing term pair 100/339\n",
      "Processing term pair 200/339\n",
      "Processing term pair 300/339\n",
      "recipient\n",
      "Processing term pair 0/370\n",
      "Processing term pair 100/370\n",
      "Processing term pair 200/370\n",
      "Processing term pair 300/370\n",
      "donor\n",
      "Processing term pair 0/458\n",
      "Processing term pair 100/458\n",
      "Processing term pair 200/458\n",
      "Processing term pair 300/458\n",
      "Processing term pair 400/458\n",
      "first-subevent\n",
      "Processing term pair 0/555\n",
      "Processing term pair 100/555\n",
      "Processing term pair 200/555\n",
      "Processing term pair 300/555\n",
      "Processing term pair 400/555\n",
      "Processing term pair 500/555\n",
      "raw-material\n",
      "Processing term pair 0/3707\n",
      "Processing term pair 100/3707\n",
      "Processing term pair 200/3707\n",
      "Processing term pair 300/3707\n",
      "Processing term pair 400/3707\n",
      "Processing term pair 500/3707\n",
      "Processing term pair 600/3707\n",
      "Processing term pair 700/3707\n",
      "Processing term pair 800/3707\n",
      "Processing term pair 900/3707\n",
      "Processing term pair 1000/3707\n",
      "Processing term pair 1100/3707\n",
      "Processing term pair 1200/3707\n",
      "Processing term pair 1300/3707\n",
      "Processing term pair 1400/3707\n",
      "Processing term pair 1500/3707\n",
      "Processing term pair 1600/3707\n",
      "Processing term pair 1700/3707\n",
      "Processing term pair 1800/3707\n",
      "Processing term pair 1900/3707\n",
      "Processing term pair 2000/3707\n",
      "Processing term pair 2100/3707\n",
      "Processing term pair 2200/3707\n",
      "Processing term pair 2300/3707\n",
      "Processing term pair 2400/3707\n",
      "Processing term pair 2500/3707\n",
      "Processing term pair 2600/3707\n",
      "Processing term pair 2700/3707\n",
      "Processing term pair 2800/3707\n",
      "Processing term pair 2900/3707\n",
      "Processing term pair 3000/3707\n",
      "Processing term pair 3100/3707\n",
      "Processing term pair 3200/3707\n",
      "Processing term pair 3300/3707\n",
      "Processing term pair 3400/3707\n",
      "Processing term pair 3500/3707\n",
      "Processing term pair 3600/3707\n",
      "Processing term pair 3700/3707\n",
      "experiencer\n",
      "Processing term pair 0/165\n",
      "Processing term pair 100/165\n",
      "beneficiary\n",
      "Processing term pair 0/20\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentences</th>\n",
       "      <th>relation</th>\n",
       "      <th>term-pair</th>\n",
       "      <th>concept-pair</th>\n",
       "      <th>tagged</th>\n",
       "      <th>synonym-tagged</th>\n",
       "      <th>count_sentences</th>\n",
       "      <th>textbook_match</th>\n",
       "      <th>term1_found</th>\n",
       "      <th>term2_found</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>&lt;e1&gt; Chemical &lt;/e1&gt; reactions alter the atomic...</td>\n",
       "      <td>subclass-of</td>\n",
       "      <td>chemical -&gt; substance</td>\n",
       "      <td>Chemical -&gt; Substance</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>17</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>&lt;e1&gt; Chemical &lt;/e1&gt; reactions obey the laws of...</td>\n",
       "      <td>subclass-of</td>\n",
       "      <td>chemical -&gt; matter</td>\n",
       "      <td>Chemical -&gt; Substance</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>5</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td></td>\n",
       "      <td>subclass-of</td>\n",
       "      <td>chemical -&gt; object</td>\n",
       "      <td>Chemical-Entity -&gt; Physical-Object</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td></td>\n",
       "      <td>subclass-of</td>\n",
       "      <td>substance -&gt; object</td>\n",
       "      <td>Substance -&gt; Tangible-Entity</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td></td>\n",
       "      <td>subclass-of</td>\n",
       "      <td>chemical entity -&gt; object</td>\n",
       "      <td>Chemical-Entity -&gt; Physical-Object</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           sentences     relation  \\\n",
       "0  <e1> Chemical </e1> reactions alter the atomic...  subclass-of   \n",
       "1  <e1> Chemical </e1> reactions obey the laws of...  subclass-of   \n",
       "2                                                     subclass-of   \n",
       "3                                                     subclass-of   \n",
       "4                                                     subclass-of   \n",
       "\n",
       "                   term-pair                        concept-pair  tagged  \\\n",
       "0      chemical -> substance               Chemical -> Substance    True   \n",
       "1         chemical -> matter               Chemical -> Substance    True   \n",
       "2         chemical -> object  Chemical-Entity -> Physical-Object   False   \n",
       "3        substance -> object        Substance -> Tangible-Entity   False   \n",
       "4  chemical entity -> object  Chemical-Entity -> Physical-Object   False   \n",
       "\n",
       "   synonym-tagged  count_sentences  textbook_match  term1_found  term2_found  \n",
       "0            True               17            True         True         True  \n",
       "1            True                5            True         True         True  \n",
       "2           False                0           False         True         True  \n",
       "3           False                0           False         True         True  \n",
       "4           False                0           False        False         True  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "found_concepts = set()\n",
    "df = {\"sentences\": [], \n",
    "      \"relation\": [], \n",
    "      \"term-pair\": [], \n",
    "      \"concept-pair\": [], \n",
    "      \"tagged\": [], \n",
    "      \"synonym-tagged\": [], \n",
    "      \"count_sentences\": [], \n",
    "      \"textbook_match\": [],\n",
    "      \"term1_found\": [],\n",
    "      \"term2_found\": []} \n",
    "\n",
    "for relation in rdb:\n",
    "    print(relation)\n",
    "    if relation == \"no-relation\":\n",
    "        continue\n",
    "    for i, term_pair in enumerate(rdb[relation]):\n",
    "        if i % 100 == 0:\n",
    "            print(f\"Processing term pair {i}/{len(rdb[relation])}\")\n",
    "        \n",
    "        sentences = rdb[relation][term_pair][\"sentences\"]\n",
    "        count_sentences = len(sentences)\n",
    "        df[\"relation\"].append(relation)\n",
    "        df[\"term-pair\"].append(term_pair)\n",
    "        concept_pair = rdb[relation][term_pair][\"concept_pair\"]\n",
    "        df[\"concept-pair\"].append(concept_pair)\n",
    "        \n",
    "        if count_sentences:\n",
    "            df[\"tagged\"].append(True)\n",
    "            df[\"textbook_match\"].append(True)\n",
    "            df[\"term1_found\"].append(True)\n",
    "            df[\"term2_found\"].append(True)\n",
    "            found_concepts.add(concept_pair)\n",
    "        else:\n",
    "            terms = term_pair.split(\" -> \")\n",
    "            df[\"tagged\"].append(False)\n",
    "            found_term1 = False\n",
    "            found_term2 = False\n",
    "            found_sentences = []\n",
    "            for sentence in bio_sentences:\n",
    "                sentence = str(sentence)\n",
    "                if terms[0] in sentence:\n",
    "                    found_term1 = True\n",
    "                if terms[1] in sentence:\n",
    "                    found_term2 = True\n",
    "                if terms[0] in sentence and terms[1] in sentence:\n",
    "                    found_sentences.append(sentence)\n",
    "            sentences = found_sentences\n",
    "            df[\"term1_found\"].append(found_term1)\n",
    "            df[\"term2_found\"].append(found_term2)\n",
    "            df[\"textbook_match\"].append(len(found_sentences) > 0)\n",
    "                \n",
    "        df[\"count_sentences\"].append(count_sentences)\n",
    "        df[\"sentences\"].append(\"\\n\".join(sentences))\n",
    "                    \n",
    "for cp in df[\"concept-pair\"]:\n",
    "    df[\"synonym-tagged\"].append(cp in found_concepts)\n",
    "\n",
    "df_df = pd.DataFrame(df)\n",
    "df_df.to_excel(f\"{data_dir}/summary/relations_classifications.xlsx\")\n",
    "df_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentences</th>\n",
       "      <th>relation</th>\n",
       "      <th>term-pair</th>\n",
       "      <th>concept-pair</th>\n",
       "      <th>tagged</th>\n",
       "      <th>synonym-tagged</th>\n",
       "      <th>count_sentences</th>\n",
       "      <th>textbook_match</th>\n",
       "      <th>term1_found</th>\n",
       "      <th>term2_found</th>\n",
       "      <th>group</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>&lt;e1&gt; Chemical &lt;/e1&gt; reactions alter the atomic...</td>\n",
       "      <td>subclass-of</td>\n",
       "      <td>chemical -&gt; substance</td>\n",
       "      <td>Chemical -&gt; Substance</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>17</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>Tagged</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>&lt;e1&gt; Chemical &lt;/e1&gt; reactions obey the laws of...</td>\n",
       "      <td>subclass-of</td>\n",
       "      <td>chemical -&gt; matter</td>\n",
       "      <td>Chemical -&gt; Substance</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>5</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>Tagged</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td></td>\n",
       "      <td>subclass-of</td>\n",
       "      <td>chemical -&gt; object</td>\n",
       "      <td>Chemical-Entity -&gt; Physical-Object</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>Terms Not Same Sentence</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td></td>\n",
       "      <td>subclass-of</td>\n",
       "      <td>substance -&gt; object</td>\n",
       "      <td>Substance -&gt; Tangible-Entity</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>Terms Not Same Sentence</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td></td>\n",
       "      <td>subclass-of</td>\n",
       "      <td>chemical entity -&gt; object</td>\n",
       "      <td>Chemical-Entity -&gt; Physical-Object</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>Missing Term</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           sentences     relation  \\\n",
       "0  <e1> Chemical </e1> reactions alter the atomic...  subclass-of   \n",
       "1  <e1> Chemical </e1> reactions obey the laws of...  subclass-of   \n",
       "2                                                     subclass-of   \n",
       "3                                                     subclass-of   \n",
       "4                                                     subclass-of   \n",
       "\n",
       "                   term-pair                        concept-pair  tagged  \\\n",
       "0      chemical -> substance               Chemical -> Substance    True   \n",
       "1         chemical -> matter               Chemical -> Substance    True   \n",
       "2         chemical -> object  Chemical-Entity -> Physical-Object   False   \n",
       "3        substance -> object        Substance -> Tangible-Entity   False   \n",
       "4  chemical entity -> object  Chemical-Entity -> Physical-Object   False   \n",
       "\n",
       "   synonym-tagged  count_sentences  textbook_match  term1_found  term2_found  \\\n",
       "0            True               17            True         True         True   \n",
       "1            True                5            True         True         True   \n",
       "2           False                0           False         True         True   \n",
       "3           False                0           False         True         True   \n",
       "4           False                0           False        False         True   \n",
       "\n",
       "                     group  \n",
       "0                   Tagged  \n",
       "1                   Tagged  \n",
       "2  Terms Not Same Sentence  \n",
       "3  Terms Not Same Sentence  \n",
       "4             Missing Term  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def group_pairs(row):\n",
    "    if row[\"tagged\"]:\n",
    "        group = \"Tagged\"\n",
    "    elif row[\"textbook_match\"]:\n",
    "        group = \"TB_Match_Not_Tagged\"\n",
    "    elif row[\"synonym-tagged\"]:\n",
    "        group = \"Synonym Tagged\"\n",
    "    elif not row[\"term1_found\"] or not row[\"term2_found\"]:\n",
    "        group = \"Missing Term\"\n",
    "    else:\n",
    "        group = \"Terms Not Same Sentence\"\n",
    "    return group\n",
    "\n",
    "df_copy = df_df.copy()\n",
    "df_copy[\"group\"] = df_copy.apply(group_pairs, axis=1)\n",
    "df_copy.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_copy.groupby([\"relation\", \"group\"])[\"sentences\"].count().reset_index().rename({\"sentences\": \"count\"}, axis=1).to_csv(f\"{data_dir}/summary/relations_matches_summary.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tokn",
   "language": "python",
   "name": "tokn"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc-autonumbering": false
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
