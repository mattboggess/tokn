{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Use device: gpu\n",
      "---\n",
      "Loading: tokenize\n",
      "With settings: \n",
      "{'model_path': '/home/ubuntu/stanfordnlp_resources/en_ewt_models/en_ewt_tokenizer.pt', 'lang': 'en', 'shorthand': 'en_ewt', 'mode': 'predict'}\n",
      "---\n",
      "Loading: pos\n",
      "With settings: \n",
      "{'model_path': '/home/ubuntu/stanfordnlp_resources/en_ewt_models/en_ewt_tagger.pt', 'pretrain_path': '/home/ubuntu/stanfordnlp_resources/en_ewt_models/en_ewt.pretrain.pt', 'lang': 'en', 'shorthand': 'en_ewt', 'mode': 'predict'}\n",
      "---\n",
      "Loading: lemma\n",
      "With settings: \n",
      "{'model_path': '/home/ubuntu/stanfordnlp_resources/en_ewt_models/en_ewt_lemmatizer.pt', 'lang': 'en', 'shorthand': 'en_ewt', 'mode': 'predict'}\n",
      "Building an attentional Seq2Seq model...\n",
      "Using a Bi-LSTM encoder\n",
      "Using soft attention for LSTM.\n",
      "Finetune all embeddings.\n",
      "[Running seq2seq lemmatizer with edit classifier]\n",
      "---\n",
      "Loading: depparse\n",
      "With settings: \n",
      "{'model_path': '/home/ubuntu/stanfordnlp_resources/en_ewt_models/en_ewt_parser.pt', 'pretrain_path': '/home/ubuntu/stanfordnlp_resources/en_ewt_models/en_ewt.pretrain.pt', 'lang': 'en', 'shorthand': 'en_ewt', 'mode': 'predict'}\n",
      "Done loading processors!\n",
      "---\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys\n",
    "import stanfordnlp\n",
    "from spacy_stanfordnlp import StanfordNLPLanguage\n",
    "import warnings\n",
    "module_path = os.path.abspath(os.path.join('../data_processing'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "#from data_processing_utils import read_spacy_docs\n",
    "\n",
    "\n",
    "snlp = stanfordnlp.Pipeline(lang=\"en\")\n",
    "nlp = StanfordNLPLanguage(snlp)\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "pre_data_dir = \"../data/preprocessed_data/\"\n",
    "te_data_dir = \"../data/term_extraction/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary of Preprocessed Textbook Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Psychology_key_terms_spacy\n",
      "Biology_2e_key_terms_spacy\n",
      "University_Physics_Volume_3_sentences_spacy\n",
      "Anatomy_and_Physiology_key_terms_spacy\n",
      "Chemistry_2e_key_terms_spacy\n",
      "Astronomy_key_terms_spacy\n",
      "University_Physics_Volume_2_key_terms_spacy\n",
      "Chemistry_2e_sentences_spacy\n",
      "Astronomy_sentences_spacy\n",
      "University_Physics_Volume_2_sentences_spacy\n",
      "Biology_2e_sentences_spacy\n",
      "Anatomy_and_Physiology_sentences_spacy\n",
      "University_Physics_Volume_3_key_terms_spacy\n",
      "Psychology_sentences_spacy\n",
      "Life_Biology_kb_key_terms_spacy\n",
      "University_Physics_Volume_1_key_terms_spacy\n",
      "Microbiology_key_terms_spacy\n",
      "Microbiology_sentences_spacy\n",
      "University_Physics_Volume_1_sentences_spacy\n",
      "Life_Biology_kb_sentences_spacy\n"
     ]
    }
   ],
   "source": [
    "textbook_data = {} \n",
    "files = os.listdir(pre_data_dir)\n",
    "for file in files:\n",
    "    if file == \"Life_Biology_sentences_spacy\" or file == \"Life_Biology_kb_lexicon.csv\" or file == \".ipynb_checkpoints\":\n",
    "        continue\n",
    "    \n",
    "    textbook = re.match(\"(.*)_(key|sentences).*\", file).group(1)\n",
    "    if textbook not in textbook_data:\n",
    "        textbook_data[textbook] = {}\n",
    "    \n",
    "    if \"sentences\" in file:\n",
    "        sentences = read_spacy_docs(f\"{pre_data_dir}/{file}\", nlp)\n",
    "        textbook_data[textbook][\"sentence_count\"] = len(sentences)\n",
    "    elif \"key_terms\" in file or \"kb_terms\" in file:\n",
    "        terms = read_spacy_docs(f\"{pre_data_dir}/{file}\", nlp)\n",
    "        terms = set([\" \".join(t.lemma_ for t in term) for term in terms])\n",
    "        textbook_data[textbook][\"terms\"] = terms \n",
    "        textbook_data[textbook][\"term_count\"] = len(terms)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Textbook Term & Sentence Counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>textbook</th>\n",
       "      <th>sentence_count</th>\n",
       "      <th>term_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Psychology</td>\n",
       "      <td>10429</td>\n",
       "      <td>848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Biology_2e</td>\n",
       "      <td>25432</td>\n",
       "      <td>2225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>University_Physics_Volume_3</td>\n",
       "      <td>12671</td>\n",
       "      <td>382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>Anatomy_and_Physiology</td>\n",
       "      <td>22440</td>\n",
       "      <td>2553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>Chemistry_2e</td>\n",
       "      <td>16720</td>\n",
       "      <td>556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>Astronomy</td>\n",
       "      <td>21668</td>\n",
       "      <td>303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>University_Physics_Volume_2</td>\n",
       "      <td>16539</td>\n",
       "      <td>279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>Life_Biology_kb</td>\n",
       "      <td>7430</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>University_Physics_Volume_1</td>\n",
       "      <td>21310</td>\n",
       "      <td>190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>Microbiology</td>\n",
       "      <td>19830</td>\n",
       "      <td>1792</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      textbook  sentence_count  term_count\n",
       "0                   Psychology           10429         848\n",
       "1                   Biology_2e           25432        2225\n",
       "2  University_Physics_Volume_3           12671         382\n",
       "3       Anatomy_and_Physiology           22440        2553\n",
       "4                 Chemistry_2e           16720         556\n",
       "5                    Astronomy           21668         303\n",
       "6  University_Physics_Volume_2           16539         279\n",
       "7              Life_Biology_kb            7430           1\n",
       "8  University_Physics_Volume_1           21310         190\n",
       "9                 Microbiology           19830        1792"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = {\"textbook\": [], \"sentence_count\": [], \"term_count\": []}\n",
    "for textbook in textbook_data:\n",
    "    df[\"textbook\"].append(textbook)\n",
    "    df[\"sentence_count\"].append(textbook_data[textbook][\"sentence_count\"])\n",
    "    df[\"term_count\"].append(textbook_data[textbook][\"term_count\"])\n",
    "df = pd.DataFrame(df)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Textbook Term Co-Occurrence Counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fraction of terms in row that overlap with column\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Psychology</th>\n",
       "      <th>Biology_2e</th>\n",
       "      <th>University_Physics_Volume_3</th>\n",
       "      <th>Anatomy_and_Physiology</th>\n",
       "      <th>Chemistry_2e</th>\n",
       "      <th>Astronomy</th>\n",
       "      <th>University_Physics_Volume_2</th>\n",
       "      <th>Life_Biology_kb</th>\n",
       "      <th>University_Physics_Volume_1</th>\n",
       "      <th>Microbiology</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>Psychology</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.108491</td>\n",
       "      <td>0.003538</td>\n",
       "      <td>0.104953</td>\n",
       "      <td>0.004717</td>\n",
       "      <td>0.005896</td>\n",
       "      <td>0.001179</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.005896</td>\n",
       "      <td>0.028302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Biology_2e</td>\n",
       "      <td>0.041348</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.004944</td>\n",
       "      <td>0.235506</td>\n",
       "      <td>0.017528</td>\n",
       "      <td>0.008989</td>\n",
       "      <td>0.004494</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.002247</td>\n",
       "      <td>0.124045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>University_Physics_Volume_3</td>\n",
       "      <td>0.007853</td>\n",
       "      <td>0.028796</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.020942</td>\n",
       "      <td>0.065445</td>\n",
       "      <td>0.054974</td>\n",
       "      <td>0.007853</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.005236</td>\n",
       "      <td>0.013089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Anatomy_and_Physiology</td>\n",
       "      <td>0.034861</td>\n",
       "      <td>0.205249</td>\n",
       "      <td>0.003134</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.010967</td>\n",
       "      <td>0.004700</td>\n",
       "      <td>0.004700</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.001958</td>\n",
       "      <td>0.058754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Chemistry_2e</td>\n",
       "      <td>0.007194</td>\n",
       "      <td>0.070144</td>\n",
       "      <td>0.044964</td>\n",
       "      <td>0.050360</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.014388</td>\n",
       "      <td>0.034173</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.012590</td>\n",
       "      <td>0.019784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Astronomy</td>\n",
       "      <td>0.016502</td>\n",
       "      <td>0.066007</td>\n",
       "      <td>0.069307</td>\n",
       "      <td>0.039604</td>\n",
       "      <td>0.026403</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.026403</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.016502</td>\n",
       "      <td>0.042904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>University_Physics_Volume_2</td>\n",
       "      <td>0.003584</td>\n",
       "      <td>0.035842</td>\n",
       "      <td>0.010753</td>\n",
       "      <td>0.043011</td>\n",
       "      <td>0.068100</td>\n",
       "      <td>0.028674</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.010753</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Life_Biology_kb</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>University_Physics_Volume_1</td>\n",
       "      <td>0.026316</td>\n",
       "      <td>0.026316</td>\n",
       "      <td>0.010526</td>\n",
       "      <td>0.026316</td>\n",
       "      <td>0.036842</td>\n",
       "      <td>0.026316</td>\n",
       "      <td>0.015789</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.010526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Microbiology</td>\n",
       "      <td>0.013393</td>\n",
       "      <td>0.154018</td>\n",
       "      <td>0.002790</td>\n",
       "      <td>0.083705</td>\n",
       "      <td>0.006138</td>\n",
       "      <td>0.007254</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.001116</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             Psychology  Biology_2e  \\\n",
       "Psychology                     1.000000    0.108491   \n",
       "Biology_2e                     0.041348    1.000000   \n",
       "University_Physics_Volume_3    0.007853    0.028796   \n",
       "Anatomy_and_Physiology         0.034861    0.205249   \n",
       "Chemistry_2e                   0.007194    0.070144   \n",
       "Astronomy                      0.016502    0.066007   \n",
       "University_Physics_Volume_2    0.003584    0.035842   \n",
       "Life_Biology_kb                0.000000    0.000000   \n",
       "University_Physics_Volume_1    0.026316    0.026316   \n",
       "Microbiology                   0.013393    0.154018   \n",
       "\n",
       "                             University_Physics_Volume_3  \\\n",
       "Psychology                                      0.003538   \n",
       "Biology_2e                                      0.004944   \n",
       "University_Physics_Volume_3                     1.000000   \n",
       "Anatomy_and_Physiology                          0.003134   \n",
       "Chemistry_2e                                    0.044964   \n",
       "Astronomy                                       0.069307   \n",
       "University_Physics_Volume_2                     0.010753   \n",
       "Life_Biology_kb                                 0.000000   \n",
       "University_Physics_Volume_1                     0.010526   \n",
       "Microbiology                                    0.002790   \n",
       "\n",
       "                             Anatomy_and_Physiology  Chemistry_2e  Astronomy  \\\n",
       "Psychology                                 0.104953      0.004717   0.005896   \n",
       "Biology_2e                                 0.235506      0.017528   0.008989   \n",
       "University_Physics_Volume_3                0.020942      0.065445   0.054974   \n",
       "Anatomy_and_Physiology                     1.000000      0.010967   0.004700   \n",
       "Chemistry_2e                               0.050360      1.000000   0.014388   \n",
       "Astronomy                                  0.039604      0.026403   1.000000   \n",
       "University_Physics_Volume_2                0.043011      0.068100   0.028674   \n",
       "Life_Biology_kb                            0.000000      0.000000   0.000000   \n",
       "University_Physics_Volume_1                0.026316      0.036842   0.026316   \n",
       "Microbiology                               0.083705      0.006138   0.007254   \n",
       "\n",
       "                             University_Physics_Volume_2  Life_Biology_kb  \\\n",
       "Psychology                                      0.001179              0.0   \n",
       "Biology_2e                                      0.004494              0.0   \n",
       "University_Physics_Volume_3                     0.007853              0.0   \n",
       "Anatomy_and_Physiology                          0.004700              0.0   \n",
       "Chemistry_2e                                    0.034173              0.0   \n",
       "Astronomy                                       0.026403              0.0   \n",
       "University_Physics_Volume_2                     1.000000              0.0   \n",
       "Life_Biology_kb                                 0.000000              1.0   \n",
       "University_Physics_Volume_1                     0.015789              0.0   \n",
       "Microbiology                                    0.000000              0.0   \n",
       "\n",
       "                             University_Physics_Volume_1  Microbiology  \n",
       "Psychology                                      0.005896      0.028302  \n",
       "Biology_2e                                      0.002247      0.124045  \n",
       "University_Physics_Volume_3                     0.005236      0.013089  \n",
       "Anatomy_and_Physiology                          0.001958      0.058754  \n",
       "Chemistry_2e                                    0.012590      0.019784  \n",
       "Astronomy                                       0.016502      0.042904  \n",
       "University_Physics_Volume_2                     0.010753      0.000000  \n",
       "Life_Biology_kb                                 0.000000      0.000000  \n",
       "University_Physics_Volume_1                     1.000000      0.010526  \n",
       "Microbiology                                    0.001116      1.000000  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "textbooks = textbook_data.keys()\n",
    "df_frac = pd.DataFrame(np.zeros((len(textbooks), len(textbooks))))\n",
    "df_frac.columns = textbooks \n",
    "df_frac.index = textbooks \n",
    "\n",
    "for i, split1 in enumerate(textbooks):\n",
    "    for j, split2 in enumerate(textbooks):\n",
    "        count_overlap = len(textbook_data[split1][\"terms\"].intersection(textbook_data[split2][\"terms\"]))\n",
    "        df_frac.iloc[i, j] = count_overlap / len(textbook_data[split1][\"terms\"])\n",
    "print(\"Fraction of terms in row that overlap with column\")\n",
    "df_frac"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary of Data Splits\n",
    "\n",
    "- num sentences\n",
    "- num terms\n",
    "- avg term appearance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>split</th>\n",
       "      <th>sentence_count</th>\n",
       "      <th>term_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>train</td>\n",
       "      <td>43670</td>\n",
       "      <td>3517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>validation</td>\n",
       "      <td>3810</td>\n",
       "      <td>871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>life_test</td>\n",
       "      <td>1757</td>\n",
       "      <td>342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>psych_test</td>\n",
       "      <td>3133</td>\n",
       "      <td>603</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        split  sentence_count  term_count\n",
       "0       train           43670        3517\n",
       "1  validation            3810         871\n",
       "2   life_test            1757         342\n",
       "3  psych_test            3133         603"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = {\"split\": [], \"sentence_count\": [], \"term_count\": []}\n",
    "for split in [\"train\", \"validation\", \"life_test\", \"psych_test\"]:\n",
    "    with open(f\"{te_data_dir}/term_extraction_{split}.json\", \"r\") as f:\n",
    "        split_data = json.load(f)\n",
    "    df[\"split\"].append(split)\n",
    "    df[\"sentence_count\"].append(len(split_data[\"sentences\"]))\n",
    "    df[\"term_count\"].append(len(split_data[\"terms\"]))\n",
    "df = pd.DataFrame(df)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Term Overlap Amongst Splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_terms = {}\n",
    "for split in [\"train\", \"validation\", \"life_test\", \"psych_test\"]:\n",
    "    with open(f\"{te_data_dir}/term_extraction_{split}.json\", \"r\") as f:\n",
    "        split_data = json.load(f)\n",
    "    split_terms[split] = set(split_data[\"terms\"].keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percent of terms for row split that overlap with column split\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train</th>\n",
       "      <th>validation</th>\n",
       "      <th>life_test</th>\n",
       "      <th>psych_test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>train</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>validation</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.289323</td>\n",
       "      <td>0.164179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>life_test</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.736842</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.347953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>psych_test</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.237148</td>\n",
       "      <td>0.197347</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            train  validation  life_test  psych_test\n",
       "train         1.0    0.000000   0.000000    0.000000\n",
       "validation    0.0    1.000000   0.289323    0.164179\n",
       "life_test     0.0    0.736842   1.000000    0.347953\n",
       "psych_test    0.0    0.237148   0.197347    1.000000"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "splits = [\"train\", \"validation\", \"life_test\", \"psych_test\"]\n",
    "df_count = pd.DataFrame(np.zeros((4, 4)))\n",
    "df_count.columns = splits \n",
    "df_count.index = splits\n",
    "df_frac = pd.DataFrame(np.zeros((4, 4)))\n",
    "df_frac.columns = splits \n",
    "df_frac.index = splits\n",
    "\n",
    "for i, split1 in enumerate(splits):\n",
    "    for j, split2 in enumerate([\"train\", \"validation\", \"life_test\", \"psych_test\"]):\n",
    "        count_overlap = len(split_terms[split1].intersection(split_terms[split2]))\n",
    "        df_count.iloc[i, j] = count_overlap\n",
    "        df_frac.iloc[i, j] = count_overlap / len(split_terms[split1])\n",
    "print(\"Percent of terms for row split that overlap with column split\")\n",
    "df_frac"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Distribution of Term Counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tokn",
   "language": "python",
   "name": "tokn"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
