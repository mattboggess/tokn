{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset Statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scraped Textbook Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>textbook</th>\n",
       "      <th>num_terms</th>\n",
       "      <th>num_sentences</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Anatomy_and_Physiology</td>\n",
       "      <td>3169</td>\n",
       "      <td>21706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Astronomy</td>\n",
       "      <td>810</td>\n",
       "      <td>18844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Biology_2e</td>\n",
       "      <td>2757</td>\n",
       "      <td>24544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Chemistry_2e</td>\n",
       "      <td>954</td>\n",
       "      <td>13799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Life_Biology</td>\n",
       "      <td>0</td>\n",
       "      <td>16673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Microbiology</td>\n",
       "      <td>4149</td>\n",
       "      <td>16190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Psychology</td>\n",
       "      <td>1086</td>\n",
       "      <td>9967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>University_Physics_Volume_1</td>\n",
       "      <td>462</td>\n",
       "      <td>15005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>University_Physics_Volume_2</td>\n",
       "      <td>466</td>\n",
       "      <td>11779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>University_Physics_Volume_3</td>\n",
       "      <td>580</td>\n",
       "      <td>9250</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      textbook  num_terms  num_sentences\n",
       "0       Anatomy_and_Physiology       3169          21706\n",
       "1                    Astronomy        810          18844\n",
       "2                   Biology_2e       2757          24544\n",
       "3                 Chemistry_2e        954          13799\n",
       "4                 Life_Biology          0          16673\n",
       "5                 Microbiology       4149          16190\n",
       "6                   Psychology       1086           9967\n",
       "7  University_Physics_Volume_1        462          15005\n",
       "8  University_Physics_Volume_2        466          11779\n",
       "9  University_Physics_Volume_3        580           9250"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "terms = pd.read_pickle(\"data/preprocessed/terms/processed_terms.pkl\")\n",
    "textbooks = ['Anatomy_and_Physiology', 'Astronomy', 'Biology_2e', 'Chemistry_2e', 'Life_Biology', 'Microbiology', 'Psychology', \n",
    "             'University_Physics_Volume_1', 'University_Physics_Volume_2', 'University_Physics_Volume_3']\n",
    "\n",
    "dataset_df = {'textbook': [], 'num_terms': [], 'num_sentences': []}\n",
    "for textbook in textbooks:\n",
    "    dataset_df['textbook'].append(textbook)\n",
    "    dataset_df['num_terms'].append(terms[terms.source == textbook].shape[0])\n",
    "    dataset_df['num_sentences'].append(pd.read_pickle(f\"data/preprocessed/clean_sentences/{textbook}_sentences.pkl\").shape[0])\n",
    "dataset_df = pd.DataFrame(dataset_df)\n",
    "dataset_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bio101 KB Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of Bio101 KB terms: 8136\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "terms = pd.read_pickle(\"data/preprocessed/terms/processed_terms.pkl\")\n",
    "print(f\"# of Bio101 KB terms: {terms[terms.source == 'kb_bio101'].shape[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>relation</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>subclass-of</td>\n",
       "      <td>18360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>synonym</td>\n",
       "      <td>12308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>has-part</td>\n",
       "      <td>6542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>result</td>\n",
       "      <td>3648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>raw-material</td>\n",
       "      <td>3526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>object</td>\n",
       "      <td>3021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>has-region</td>\n",
       "      <td>2976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>subevent</td>\n",
       "      <td>2894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>base</td>\n",
       "      <td>2396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>agent</td>\n",
       "      <td>1807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>possesses</td>\n",
       "      <td>1744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>is-inside</td>\n",
       "      <td>1048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>encloses</td>\n",
       "      <td>1022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>next-event</td>\n",
       "      <td>895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>first-subevent</td>\n",
       "      <td>539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>element</td>\n",
       "      <td>533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>donor</td>\n",
       "      <td>470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>is-between</td>\n",
       "      <td>461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>size</td>\n",
       "      <td>428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>recipient</td>\n",
       "      <td>383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>instrument</td>\n",
       "      <td>333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>is-at</td>\n",
       "      <td>307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>structural-complexity</td>\n",
       "      <td>301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>does-not-enclose</td>\n",
       "      <td>219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>is-outside</td>\n",
       "      <td>196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>shape</td>\n",
       "      <td>188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>abuts</td>\n",
       "      <td>162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>experiencer</td>\n",
       "      <td>159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>atomic-weight</td>\n",
       "      <td>152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>volume</td>\n",
       "      <td>108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>length</td>\n",
       "      <td>101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>is-across</td>\n",
       "      <td>101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>is-near</td>\n",
       "      <td>68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>is-along</td>\n",
       "      <td>65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>diameter</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>is-above</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>is-below</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>beneficiary</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>thickness</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>wavelength</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>mass</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>has-ion</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>is-opposite</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>height</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>is-on</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>is-oriented-toward</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>specific-surface-area</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>has-on-it</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>is-beside</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>is-facing</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>width</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>area</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>surface-area</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>depth</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>is-over</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>is-under</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>is-parallel-to</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>is-behind</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>angle</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 relation  count\n",
       "1             subclass-of  18360\n",
       "0                 synonym  12308\n",
       "2                has-part   6542\n",
       "47                 result   3648\n",
       "56           raw-material   3526\n",
       "49                 object   3021\n",
       "4              has-region   2976\n",
       "51               subevent   2894\n",
       "46                   base   2396\n",
       "50                  agent   1807\n",
       "3               possesses   1744\n",
       "5               is-inside   1048\n",
       "6                encloses   1022\n",
       "48             next-event    895\n",
       "55         first-subevent    539\n",
       "15                element    533\n",
       "54                  donor    470\n",
       "11             is-between    461\n",
       "10                   size    428\n",
       "53              recipient    383\n",
       "52             instrument    333\n",
       "8                   is-at    307\n",
       "9   structural-complexity    301\n",
       "12       does-not-enclose    219\n",
       "17             is-outside    196\n",
       "21                  shape    188\n",
       "16                  abuts    162\n",
       "57            experiencer    159\n",
       "26          atomic-weight    152\n",
       "18                 volume    108\n",
       "27                 length    101\n",
       "20              is-across    101\n",
       "24                is-near     68\n",
       "29               is-along     65\n",
       "22               diameter     29\n",
       "25               is-above     25\n",
       "7                is-below     25\n",
       "58            beneficiary     20\n",
       "36              thickness     19\n",
       "34             wavelength     18\n",
       "19                   mass     14\n",
       "35                has-ion     14\n",
       "28            is-opposite     12\n",
       "30                 height     11\n",
       "32                  is-on     10\n",
       "13     is-oriented-toward     10\n",
       "23  specific-surface-area     10\n",
       "40              has-on-it     10\n",
       "38              is-beside      8\n",
       "14              is-facing      8\n",
       "43                  width      7\n",
       "42                   area      6\n",
       "37           surface-area      6\n",
       "31                  depth      3\n",
       "41                is-over      2\n",
       "44               is-under      2\n",
       "33         is-parallel-to      2\n",
       "45              is-behind      1\n",
       "39                  angle      1"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pickle\n",
    "with open(\"data/preprocessed/kb_bio101_relations_db.pkl\", 'rb') as fid:\n",
    "    db = pickle.load(fid)\n",
    "df = {'relation': [], 'count': []}\n",
    "for r in db:\n",
    "    df['relation'].append(r)\n",
    "    df['count'].append(len(db[r]))\n",
    "df = pd.DataFrame(df).sort_values(['count'], ascending=False)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Term Extraction Data Splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>split</th>\n",
       "      <th>num_sentences</th>\n",
       "      <th>num_terms</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>train</td>\n",
       "      <td>58057</td>\n",
       "      <td>7041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>dev</td>\n",
       "      <td>206</td>\n",
       "      <td>283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>test</td>\n",
       "      <td>608</td>\n",
       "      <td>500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   split  num_sentences  num_terms\n",
       "0  train          58057       7041\n",
       "1    dev            206        283\n",
       "2   test            608        500"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "splits_df = {'split': [], 'num_sentences': [], 'num_terms': []}\n",
    "for split in ['train', 'dev', 'test']:\n",
    "    df = pd.read_pickle(f\"data/term_extraction/term_extraction_{split}.pkl\")\n",
    "    terms = set()\n",
    "    for t in df.terms:\n",
    "        terms = terms | t\n",
    "    if split == 'train':\n",
    "        tts = terms\n",
    "    elif split == 'dev':\n",
    "        dts = terms\n",
    "    splits_df['split'].append(split)\n",
    "    splits_df['num_sentences'].append(df.shape[0])\n",
    "    splits_df['num_terms'].append(len(terms))\n",
    "splits_df = pd.DataFrame(splits_df)\n",
    "splits_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Term Extraction Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'loss': 0.6661314779114955,\n",
       " 'accuracy': 0.9911635315533981,\n",
       " 'token_macro_f1': 0.7390851418763833,\n",
       " 'token_macro_precision': 0.7494545950033281,\n",
       " 'token_macro_recall': 0.7348825726831907,\n",
       " 'token_micro_f1': 0.7456382001836548,\n",
       " 'token_micro_precision': 0.744954128440367,\n",
       " 'token_micro_recall': 0.7463235294117647,\n",
       " 'term_f1': 0.6594982078853046,\n",
       " 'term_recall': 0.6501766784452296,\n",
       " 'term_precision': 0.6690909090909091}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "with open('term_extraction/saved/models/BertSoftmax/0624_025137/dev-metrics.json', 'r') as fid:\n",
    "    metrics = json.load(fid)\n",
    "metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'loss': 1.40711688367944,\n",
       " 'accuracy': 0.986681486430921,\n",
       " 'token_macro_f1': 0.5589522568377555,\n",
       " 'token_macro_precision': 0.604545818324427,\n",
       " 'token_macro_recall': 0.523563109543713,\n",
       " 'token_micro_f1': 0.5822563744324136,\n",
       " 'token_micro_precision': 0.6409073433294886,\n",
       " 'token_micro_recall': 0.53344,\n",
       " 'term_f1': 0.551341350601295,\n",
       " 'term_recall': 0.596,\n",
       " 'term_precision': 0.5129087779690189}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "with open('term_extraction/saved/models/BertSoftmax/0624_025137/test-metrics.json', 'r') as fid:\n",
    "    metrics = json.load(fid)\n",
    "metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Relation Extraction Data Splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>split</th>\n",
       "      <th>instances</th>\n",
       "      <th>sentences</th>\n",
       "      <th>term_pairs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>train</td>\n",
       "      <td>167093</td>\n",
       "      <td>29830</td>\n",
       "      <td>105236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>dev</td>\n",
       "      <td>11935</td>\n",
       "      <td>2065</td>\n",
       "      <td>8642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>test</td>\n",
       "      <td>3106</td>\n",
       "      <td>491</td>\n",
       "      <td>2582</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   split  instances  sentences  term_pairs\n",
       "0  train     167093      29830      105236\n",
       "1    dev      11935       2065        8642\n",
       "2   test       3106        491        2582"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "splits_df = {'split': [], 'instances': [], 'sentences': [], 'term_pairs': []}\n",
    "for split in ['train', 'dev', 'test']:\n",
    "    df = pd.read_pickle(f\"data/relation_extraction/{split}.pkl\")\n",
    "    splits_df['split'].append(split)\n",
    "    splits_df['instances'].append(df.shape[0])\n",
    "    splits_df['sentences'].append(len(df.sentence.unique()))\n",
    "    splits_df['term_pairs'].append(len(df.term_pair.unique()))\n",
    "splits_df = pd.DataFrame(splits_df)\n",
    "splits_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "gold_label\n",
       "HAS-PART/REGION    0.037956\n",
       "OTHER              0.880938\n",
       "PART/REGION-OF     0.037453\n",
       "SUBCLASS           0.017009\n",
       "SUPERCLASS         0.021701\n",
       "SYNONYM            0.004943\n",
       "Name: term_pair, dtype: float64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dev = pd.read_pickle(f\"data/relation_extraction/dev.pkl\")\n",
    "dev.groupby('gold_label').term_pair.count() / dev.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "gold_label\n",
       "HAS-PART/REGION    0.004829\n",
       "OTHER              0.969736\n",
       "PART/REGION-OF     0.004507\n",
       "SUBCLASS           0.005795\n",
       "SUPERCLASS         0.014166\n",
       "SYNONYM            0.000966\n",
       "Name: term_pair, dtype: float64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = pd.read_pickle(f\"data/relation_extraction/test.pkl\")\n",
    "test.groupby('gold_label').term_pair.count() / test.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Relation Extraction Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 precision    recall  f1-score   support\n",
      "\n",
      "       SUBCLASS       0.71      0.78      0.75       203\n",
      "     SUPERCLASS       0.61      0.67      0.64       259\n",
      "        SYNONYM       0.62      0.75      0.68        59\n",
      "HAS-PART/REGION       0.63      0.34      0.44       452\n",
      " PART/REGION-OF       0.46      0.15      0.23       447\n",
      "\n",
      "      micro avg       0.62      0.42      0.50      1420\n",
      "      macro avg       0.61      0.54      0.55      1420\n",
      "   weighted avg       0.58      0.42      0.47      1420\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with open('relation_extraction/saved/models/soft_label/0626_160708/dev-instance-metrics.txt', 'r') as fid:\n",
    "    print(fid.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 precision    recall  f1-score   support\n",
      "\n",
      "       SUBCLASS       0.31      0.89      0.46        18\n",
      "     SUPERCLASS       0.52      0.77      0.62        44\n",
      "        SYNONYM       0.25      1.00      0.40         3\n",
      "HAS-PART/REGION       0.14      0.40      0.21        15\n",
      " PART/REGION-OF       0.21      0.86      0.33        14\n",
      "\n",
      "      micro avg       0.31      0.76      0.44        94\n",
      "      macro avg       0.29      0.78      0.40        94\n",
      "   weighted avg       0.36      0.76      0.47        94\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with open('relation_extraction/saved/models/soft_label/0626_160708/test-instance-metrics.txt', 'r') as fid:\n",
    "    print(fid.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Term Pair Metrics:\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "       SUBCLASS       0.71      0.80      0.75       163\n",
      "     SUPERCLASS       0.62      0.69      0.66       221\n",
      "        SYNONYM       0.58      0.70      0.63        47\n",
      "HAS-PART/REGION       0.60      0.50      0.55       225\n",
      " PART/REGION-OF       0.39      0.19      0.26       206\n",
      "\n",
      "      micro avg       0.61      0.54      0.57       862\n",
      "      macro avg       0.58      0.58      0.57       862\n",
      "   weighted avg       0.58      0.54      0.55       862\n",
      "\n",
      "Bio101 Term Pair Metrics:\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "       SUBCLASS       0.65      0.25      0.36       163\n",
      "     SUPERCLASS       0.71      0.24      0.35       221\n",
      "        SYNONYM       0.50      0.21      0.30        47\n",
      "HAS-PART/REGION       0.88      0.65      0.75       225\n",
      " PART/REGION-OF       0.93      0.61      0.74       206\n",
      "\n",
      "      micro avg       0.82      0.44      0.57       862\n",
      "      macro avg       0.73      0.39      0.50       862\n",
      "   weighted avg       0.78      0.44      0.55       862\n",
      "\n",
      "Label Fn Term Pair Metrics:\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "       SUBCLASS       0.66      0.69      0.68       163\n",
      "     SUPERCLASS       0.69      0.60      0.64       221\n",
      "        SYNONYM       0.51      0.45      0.48        47\n",
      "HAS-PART/REGION       0.80      0.38      0.52       225\n",
      " PART/REGION-OF       0.49      0.15      0.22       206\n",
      "\n",
      "      micro avg       0.67      0.44      0.53       862\n",
      "      macro avg       0.63      0.45      0.51       862\n",
      "   weighted avg       0.66      0.44      0.51       862\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with open('relation_extraction/saved/models/soft_label/0626_160708/dev-term-pair-metrics.txt', 'r') as fid:\n",
    "    print(fid.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Term Pair Metrics:\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "       SUBCLASS       0.32      0.88      0.47        17\n",
      "     SUPERCLASS       0.53      0.76      0.62        41\n",
      "        SYNONYM       0.25      1.00      0.40         3\n",
      "HAS-PART/REGION       0.14      0.50      0.22        12\n",
      " PART/REGION-OF       0.17      0.80      0.28        10\n",
      "\n",
      "      micro avg       0.30      0.76      0.43        83\n",
      "      macro avg       0.28      0.79      0.40        83\n",
      "   weighted avg       0.37      0.76      0.48        83\n",
      "\n",
      "Bio101 Term Pair Metrics:\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "       SUBCLASS       0.33      0.06      0.10        17\n",
      "     SUPERCLASS       0.69      0.22      0.33        41\n",
      "        SYNONYM       0.00      0.00      0.00         3\n",
      "HAS-PART/REGION       0.55      0.50      0.52        12\n",
      " PART/REGION-OF       0.50      0.40      0.44        10\n",
      "\n",
      "      micro avg       0.57      0.24      0.34        83\n",
      "      macro avg       0.41      0.24      0.28        83\n",
      "   weighted avg       0.55      0.24      0.31        83\n",
      "\n",
      "Label Fn Term Pair Metrics:\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "       SUBCLASS       0.39      0.94      0.55        17\n",
      "     SUPERCLASS       0.67      0.73      0.70        41\n",
      "        SYNONYM       0.30      1.00      0.46         3\n",
      "HAS-PART/REGION       0.27      0.33      0.30        12\n",
      " PART/REGION-OF       0.12      0.20      0.15        10\n",
      "\n",
      "      micro avg       0.43      0.66      0.52        83\n",
      "      macro avg       0.35      0.64      0.43        83\n",
      "   weighted avg       0.47      0.66      0.54        83\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with open('relation_extraction/saved/models/soft_label/0626_160708/test-term-pair-metrics.txt', 'r') as fid:\n",
    "    print(fid.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 precision    recall  f1-score   support\n",
      "\n",
      "       SUBCLASS       0.65      0.79      0.71       203\n",
      "     SUPERCLASS       0.73      0.55      0.63       259\n",
      "        SYNONYM       0.57      0.58      0.57        59\n",
      "HAS-PART/REGION       0.57      0.35      0.43       452\n",
      " PART/REGION-OF       0.47      0.08      0.13       447\n",
      "\n",
      "      micro avg       0.62      0.37      0.47      1420\n",
      "      macro avg       0.60      0.47      0.50      1420\n",
      "   weighted avg       0.58      0.37      0.42      1420\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with open('relation_extraction/saved/models/hard_label/0626_231929/dev-instance-metrics.txt', 'r') as fid:\n",
    "    print(fid.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 precision    recall  f1-score   support\n",
      "\n",
      "       SUBCLASS       0.36      0.94      0.52        18\n",
      "     SUPERCLASS       0.70      0.70      0.70        44\n",
      "        SYNONYM       0.38      1.00      0.55         3\n",
      "HAS-PART/REGION       0.19      0.33      0.24        15\n",
      " PART/REGION-OF       0.25      0.21      0.23        14\n",
      "\n",
      "      micro avg       0.43      0.63      0.51        94\n",
      "      macro avg       0.38      0.64      0.45        94\n",
      "   weighted avg       0.48      0.63      0.52        94\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with open('relation_extraction/saved/models/hard_label/0626_231929/test-instance-metrics.txt', 'r') as fid:\n",
    "    print(fid.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Term Pair Metrics:\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "       SUBCLASS       0.64      0.81      0.72       163\n",
      "     SUPERCLASS       0.76      0.56      0.64       221\n",
      "        SYNONYM       0.51      0.53      0.52        47\n",
      "HAS-PART/REGION       0.55      0.52      0.54       225\n",
      " PART/REGION-OF       0.45      0.15      0.22       206\n",
      "\n",
      "      micro avg       0.61      0.50      0.55       862\n",
      "      macro avg       0.58      0.51      0.53       862\n",
      "   weighted avg       0.60      0.50      0.52       862\n",
      "\n",
      "Bio101 Term Pair Metrics:\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "       SUBCLASS       0.65      0.25      0.36       163\n",
      "     SUPERCLASS       0.71      0.24      0.35       221\n",
      "        SYNONYM       0.50      0.21      0.30        47\n",
      "HAS-PART/REGION       0.88      0.65      0.75       225\n",
      " PART/REGION-OF       0.93      0.61      0.74       206\n",
      "\n",
      "      micro avg       0.82      0.44      0.57       862\n",
      "      macro avg       0.73      0.39      0.50       862\n",
      "   weighted avg       0.78      0.44      0.55       862\n",
      "\n",
      "Label Fn Term Pair Metrics:\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "       SUBCLASS       0.66      0.69      0.68       163\n",
      "     SUPERCLASS       0.69      0.60      0.64       221\n",
      "        SYNONYM       0.51      0.45      0.48        47\n",
      "HAS-PART/REGION       0.80      0.38      0.52       225\n",
      " PART/REGION-OF       0.49      0.15      0.22       206\n",
      "\n",
      "      micro avg       0.67      0.44      0.53       862\n",
      "      macro avg       0.63      0.45      0.51       862\n",
      "   weighted avg       0.66      0.44      0.51       862\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with open('relation_extraction/saved/models/hard_label/0626_231929/dev-term-pair-metrics.txt', 'r') as fid:\n",
    "    print(fid.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Term Pair Metrics:\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "       SUBCLASS       0.36      0.94      0.52        17\n",
      "     SUPERCLASS       0.72      0.68      0.70        41\n",
      "        SYNONYM       0.38      1.00      0.55         3\n",
      "HAS-PART/REGION       0.19      0.42      0.26        12\n",
      " PART/REGION-OF       0.27      0.30      0.29        10\n",
      "\n",
      "      micro avg       0.43      0.66      0.52        83\n",
      "      macro avg       0.38      0.67      0.46        83\n",
      "   weighted avg       0.50      0.66      0.54        83\n",
      "\n",
      "Bio101 Term Pair Metrics:\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "       SUBCLASS       0.33      0.06      0.10        17\n",
      "     SUPERCLASS       0.69      0.22      0.33        41\n",
      "        SYNONYM       0.00      0.00      0.00         3\n",
      "HAS-PART/REGION       0.55      0.50      0.52        12\n",
      " PART/REGION-OF       0.50      0.40      0.44        10\n",
      "\n",
      "      micro avg       0.57      0.24      0.34        83\n",
      "      macro avg       0.41      0.24      0.28        83\n",
      "   weighted avg       0.55      0.24      0.31        83\n",
      "\n",
      "Label Fn Term Pair Metrics:\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "       SUBCLASS       0.39      0.94      0.55        17\n",
      "     SUPERCLASS       0.67      0.73      0.70        41\n",
      "        SYNONYM       0.30      1.00      0.46         3\n",
      "HAS-PART/REGION       0.27      0.33      0.30        12\n",
      " PART/REGION-OF       0.12      0.20      0.15        10\n",
      "\n",
      "      micro avg       0.43      0.66      0.52        83\n",
      "      macro avg       0.35      0.64      0.43        83\n",
      "   weighted avg       0.47      0.66      0.54        83\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with open('relation_extraction/saved/models/hard_label/0626_231929/test-term-pair-metrics.txt', 'r') as fid:\n",
    "    print(fid.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_pytorch_p36)",
   "language": "python",
   "name": "conda_pytorch_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
