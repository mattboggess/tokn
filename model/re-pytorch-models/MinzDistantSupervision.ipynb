{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Use device: cpu\n",
      "---\n",
      "Loading: tokenize\n",
      "With settings: \n",
      "{'model_path': '/Users/hanlin/stanfordnlp_resources/en_ewt_models/en_ewt_tokenizer.pt', 'lang': 'en', 'shorthand': 'en_ewt', 'mode': 'predict'}\n",
      "---\n",
      "Loading: pos\n",
      "With settings: \n",
      "{'model_path': '/Users/hanlin/stanfordnlp_resources/en_ewt_models/en_ewt_tagger.pt', 'pretrain_path': '/Users/hanlin/stanfordnlp_resources/en_ewt_models/en_ewt.pretrain.pt', 'lang': 'en', 'shorthand': 'en_ewt', 'mode': 'predict'}\n",
      "---\n",
      "Loading: lemma\n",
      "With settings: \n",
      "{'model_path': '/Users/hanlin/stanfordnlp_resources/en_ewt_models/en_ewt_lemmatizer.pt', 'lang': 'en', 'shorthand': 'en_ewt', 'mode': 'predict'}\n",
      "Building an attentional Seq2Seq model...\n",
      "Using a Bi-LSTM encoder\n",
      "Using soft attention for LSTM.\n",
      "Finetune all embeddings.\n",
      "[Running seq2seq lemmatizer with edit classifier]\n",
      "---\n",
      "Loading: depparse\n",
      "With settings: \n",
      "{'model_path': '/Users/hanlin/stanfordnlp_resources/en_ewt_models/en_ewt_parser.pt', 'pretrain_path': '/Users/hanlin/stanfordnlp_resources/en_ewt_models/en_ewt.pretrain.pt', 'lang': 'en', 'shorthand': 'en_ewt', 'mode': 'predict'}\n",
      "Done loading processors!\n",
      "---\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "import spacy\n",
    "import stanfordnlp\n",
    "import json\n",
    "import os\n",
    "import gensim\n",
    "import importlib  \n",
    "\n",
    "from gensim.models import KeyedVectors\n",
    "from spacy_stanfordnlp import StanfordNLPLanguage\n",
    "from model.data_loaders import RelationDataset\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn import svm\n",
    "\n",
    "snlp = stanfordnlp.Pipeline(lang=\"en\")\n",
    "nlp = StanfordNLPLanguage(snlp)\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Microsoft Microsoft PROPN NNP nsubj\n",
      "is be AUX VBZ aux\n",
      "looking look VERB VBG root\n",
      "at at SCONJ IN mark\n",
      "buying buy VERB VBG advcl\n",
      "U.K. U.K. PROPN NNP compound\n",
      "startup startup NOUN NN obj\n",
      "for for ADP IN case\n",
      "$ $ SYM $ obl\n",
      "1 1 NUM CD compound\n",
      "billion billion NUM CD nummod\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(\"Microsoft is looking at buying U.K. startup for $1 billion\")\n",
    "\n",
    "for token in doc:\n",
    "    print(token.text, token.lemma_, token.pos_, token.tag_, token.dep_)\n",
    "\n",
    "for ent in doc.ents:\n",
    "    print(ent.label_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import json \n",
    "import numpy as np\n",
    "\n",
    "ID2WORD = json.load(open(os.path.join(\"../../data/relation_extraction\", 'id2word.json')))\n",
    "all_tokens = set()\n",
    "SPACY_FEATURES = ['LS',\n",
    " 'X',\n",
    " 'PROPN',\n",
    " 'SYM',\n",
    " 'INTJ',\n",
    " 'UH',\n",
    " 'NOUN',\n",
    " 'AFX',\n",
    " 'NNP',\n",
    " 'PUNCT',\n",
    " 'NFP',\n",
    " 'PRP',\n",
    " 'NN',\n",
    " 'PRON',\n",
    " 'UNK']\n",
    "\n",
    "def bag_of_words_featurizer(bag_of_words, bag_of_words_actual):\n",
    "    \"\"\"\n",
    "    sentence is in id \n",
    "    \"\"\"\n",
    "    feat_len = len(ID2WORD)\n",
    "    feat_vec = np.zeros(feat_len)\n",
    "    for sent_index, sentence in enumerate(bag_of_words):\n",
    "        words = bag_of_words_actual[sent_index]\n",
    "        for word_id in sentence:\n",
    "            feat_vec[word_id] += 1\n",
    "    feat_vec/= len(bag_of_words)\n",
    "    return feat_vec\n",
    "\n",
    "\n",
    "def word_vec_bag_of_words_featurizer(model, bag_of_words, bag_of_words_actual):\n",
    "    \"\"\"\n",
    "    sentence is in id \n",
    "    \"\"\"\n",
    "    feat_len = 300\n",
    "    feat_vec = np.zeros(feat_len)\n",
    "    feat_vecs = []\n",
    "    for sent_index, sentence in enumerate(bag_of_words):\n",
    "        words = bag_of_words_actual[sent_index]\n",
    "        for word in words:\n",
    "            word_vec = feat_vec\n",
    "            if word in model.wv.vocab:\n",
    "                word_vec = model[word]\n",
    "            feat_vecs.append(word_vec)\n",
    "    if feat_vecs == []:\n",
    "        feat_vec = model['UNK']\n",
    "    else:\n",
    "        feat_vec = np.mean(np.array(feat_vecs), axis=0)\n",
    "    return feat_vec\n",
    "\n",
    "\n",
    "def loadPretrainedWordVectors(pretrained_path):\n",
    "    return KeyedVectors.load_word2vec_format(pretrained_path, binary=True)\n",
    "\n",
    "def loadFastTextWordVectors(pretrained_path):\n",
    "    return KeyedVectors.load_word2vec_format(pretrained_path, binary=False)\n",
    "\n",
    "def spacy_features(word_pair):\n",
    "    spacy_feat = [0 for i in range(len(SPACY_FEATURES))]\n",
    "    for i in range(2):\n",
    "        try:\n",
    "            featurized_phrase = nlp(word_pair[i])\n",
    "            for token in featurized_phrase:\n",
    "                if token.pos_ in SPACY_FEATURES:\n",
    "                    spacy_feat[SPACY_FEATURES.index(token.pos_)] += 1\n",
    "                else:\n",
    "                    spacy_feat[-1] += 1\n",
    "                if token.tag_ in SPACY_FEATURES:\n",
    "                    spacy_feat[SPACY_FEATURES.index(token.tag_)] += 1\n",
    "                else:\n",
    "                    spacy_feat[-1] += 1\n",
    "        except:\n",
    "            print(word_pair)\n",
    "            return spacy_feat\n",
    "    return spacy_feat\n",
    "    \n",
    "\n",
    "def edit_distance(word_pair):\n",
    "    \"\"\"\n",
    "    sentence is in id \n",
    "    \"\"\" \n",
    "    return nltk.edit_distance(word_pair[0], word_pair[1])\n",
    "\n",
    "def is_sub_word(word_pair):\n",
    "    return 1 if word_pair[0] in word_pair[1] else 0\n",
    "\n",
    "\n",
    "def construct_minz_dataset_word_vec(word_vec_model, dataset):\n",
    "    X = []\n",
    "    y = []\n",
    "    index = 0\n",
    "    for bag_of_words, y_label, word_pair, pad_mask, e1_mask, e2_mask in dataset:\n",
    "        words = []\n",
    "        bag_of_words = bag_of_words.numpy()\n",
    "        if len(bag_of_words) != 0:\n",
    "            index += 1\n",
    "            for bag_of_word in bag_of_words:\n",
    "                words.append([ID2WORD[str(id)] for id in bag_of_word])\n",
    "            feat_vec = word_vec_bag_of_words_featurizer(word_vec_model, bag_of_words, words)\n",
    "            X.append(feat_vec)\n",
    "            y.append(y_label.numpy()[0])\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "def construct_minz_dataset(dataset):\n",
    "    X = []\n",
    "    y = []\n",
    "    index = 0\n",
    "    for bag_of_words, y_label, word_pair, pad_mask, e1_mask, e2_mask in dataset:\n",
    "        words = []\n",
    "        bag_of_words = bag_of_words.numpy()\n",
    "        if len(bag_of_words) != 0:\n",
    "            index += 1\n",
    "            for bag_of_word in bag_of_words:\n",
    "                words.append([ID2WORD[str(id)] for id in bag_of_word])\n",
    "            feat_vec = bag_of_words_featurizer(bag_of_words, words)\n",
    "#             feat_vec = np.concatenate([feat_vec, spacy_features(word_pair)])\n",
    "            np.append(feat_vec, edit_distance(word_pair))\n",
    "            np.append(feat_vec, is_sub_word(word_pair))\n",
    "            X.append(feat_vec)\n",
    "            y.append(y_label.numpy()[0])\n",
    "    return np.array(X), np.array(y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_relation_name(relations, y_label):\n",
    "    return relations[y_label]\n",
    "\n",
    "def dump_tp_fp(y_pred, y_true, relations, rel_dataset):\n",
    "    if \"no-relation\" not in relations:\n",
    "        relations.insert(0, \"no-relation\")\n",
    "    i = 0\n",
    "    rel_dict = {}\n",
    "    for relation in relations:\n",
    "        rel_dict[relation] = {\"TP\" : [], \"FP\" : []}\n",
    "    for bag_of_words, y_label, word_pair, pad_mask, e1_mask, e2_mask in rel_dataset:\n",
    "        relation_name = get_relation_name(relations, y_pred[i])\n",
    "        if len(bag_of_words) != 0:\n",
    "            if y_true[i]==y_pred[i]:\n",
    "                rel_dict[relation_name][\"TP\"].append(word_pair)\n",
    "            if y_true[i] != y_pred[i]:\n",
    "                rel_dict[relation_name][\"FP\"].append(word_pair)\n",
    "            i += 1\n",
    "    json.dump(rel_dict, open(\"relations_tp_fp.json\", \"w\"), indent=4)\n",
    "    return rel_dict\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"../../data/relation_extraction\"\n",
    "rel_dataset_train = RelationDataset(data_dir=data_dir, split=\"train\", relations=[\"taxonomy\", \"meronym\", \"spatial\", \"event_structure\"], embedding_type=\"custom\", max_sent_length=256)\n",
    "rel_dataset_test = RelationDataset(data_dir=data_dir, split=\"test\",  relations=[\"taxonomy\", \"meronym\", \"spatial\", \"event_structure\"], embedding_type=\"custom\", max_sent_length=256)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "id2vocab = json.load(open(os.path.join(\"../../data/relation_extraction\", 'id2word.json')))\n",
    "X_train, y_train = construct_minz_dataset(rel_dataset_train)\n",
    "X_test, y_test = construct_minz_dataset(rel_dataset_test)\n",
    "np.unique(y_train, return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Includes spacy features\n",
    "clf = LogisticRegression(random_state=0, solver='lbfgs')\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "print(\"Accuracy\", clf.score(X_test, y_test))\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(clf.coef_) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['LS',\n",
       " 'X',\n",
       " 'PROPN',\n",
       " 'SYM',\n",
       " 'INTJ',\n",
       " 'UH',\n",
       " 'NOUN',\n",
       " 'root',\n",
       " 'AFX',\n",
       " 'NNP',\n",
       " 'PUNCT',\n",
       " 'NFP',\n",
       " 'PRP',\n",
       " 'NN',\n",
       " 'PRON']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_tokens\n",
    "spacy_feat = list(all_tokens)\n",
    "spacy_feat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['LS',\n",
       " 'X',\n",
       " 'PROPN',\n",
       " 'SYM',\n",
       " 'INTJ',\n",
       " 'UH',\n",
       " 'NOUN',\n",
       " 'AFX',\n",
       " 'NNP',\n",
       " 'PUNCT',\n",
       " 'NFP',\n",
       " 'PRP',\n",
       " 'NN',\n",
       " 'PRON',\n",
       " 'UNK']"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spacy_feat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 0.5860215053763441\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.52      0.55       185\n",
      "           1       0.58      0.65      0.61       187\n",
      "\n",
      "    accuracy                           0.59       372\n",
      "   macro avg       0.59      0.59      0.58       372\n",
      "weighted avg       0.59      0.59      0.58       372\n",
      "\n",
      "[[ 0.00158959  0.         -0.07175936 ...  0.          0.\n",
      "   0.        ]]\n"
     ]
    }
   ],
   "source": [
    "# Non-spacy feat\n",
    "clf = LogisticRegression(random_state=0, solver='lbfgs')\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "print(\"Accuracy\", clf.score(X_test, y_test))\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(clf.coef_) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Word vector experiments (Fast text and word2vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = loadFastTextWordVectors('wiki-news-300d-1M-subword.vec')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_wordVec = loadPretrainedWordVectors('GoogleNews-vectors-negative300.bin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = construct_minz_dataset_word_vec(model, rel_dataset_train)\n",
    "X_test, y_test = construct_minz_dataset_word_vec(model, rel_dataset_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 0.5725806451612904\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.21      0.33       185\n",
      "           1       0.54      0.93      0.69       187\n",
      "\n",
      "    accuracy                           0.57       372\n",
      "   macro avg       0.65      0.57      0.51       372\n",
      "weighted avg       0.65      0.57      0.51       372\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf = LogisticRegression(random_state=0, solver='lbfgs')\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "print(\"Accuracy\", clf.score(X_test, y_test))\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = construct_minz_dataset_word_vec(model_wordVec, rel_dataset_train)\n",
    "X_test, y_test = construct_minz_dataset_word_vec(model_wordVec, rel_dataset_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 0.5456989247311828\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.26      0.37       185\n",
      "           1       0.53      0.82      0.65       187\n",
      "\n",
      "    accuracy                           0.55       372\n",
      "   macro avg       0.56      0.54      0.51       372\n",
      "weighted avg       0.56      0.55      0.51       372\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf = LogisticRegression(random_state=0, solver='lbfgs')\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "print(\"Accuracy\", clf.score(X_test, y_test))\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'no-relation': {'TP': ['phage -> lytic cycle', 'species -> oviparous', 'tissue -> physician', 'nerve -> calcium atom', 'carbon dioxide -> heart', 'seedling -> fluorescent substance', 'vascular plant -> blood vessel', 'energy -> chemoheterotroph', 'bacteriophage -> infection', 'excretory organ -> digestive system', 'condition -> theory', 'earth -> plant', 'cell adhesion molecule -> close', 'zygote -> centriole', 'pigment -> kidney', 'nerve impulse -> water balance', 'hydrogen atom -> nucleus', 'parasite -> compound', 'activate -> determination', 'carrier -> free - energy', 'colon -> molecule', 'water -> create', 'mitochondrial membrane -> energy', 'antidiuretic hormone -> norepinephrine', 'vein -> oxygen atom', 'cytoplasm -> influence', 'lake -> bird', 'touch -> marine mammal', 'make -> ferment', 'free - energy -> FAD', 'natural selection -> offspring', 'increase -> consumer', 'fungus -> reproduce', 'riboflavin -> whole', 'mutation -> host', 'lead atom -> body cavity', 'C4 plant -> soybean plant', 'differentiate -> antigen', 'clotting factor -> bind', 'resting potential -> diffuse', 'induced fit -> protein', 'cortex -> develop', 'breathing -> decrease', 'pair -> tubule', 'people -> smallpox', 'diffuse -> synthesis of ATP', 'insect -> termite', 'mathematical model -> geneticist', 'humoral immune response -> infected cell', 'information -> presynaptic cell', 'nitrogen atom -> fall', 'flow -> cell membrane', 'mollusc -> calcium atom', 'lead -> death', 'optimal foraging -> feeding behavior', 'digestive system -> flora', 'phospholipid bilayer -> bind', 'chloroplast -> autotroph', 'response -> fat substance', 'isoleucine -> alcohol dehydrogenase', 'fragment -> break', 'signal -> tendon', 'seedling -> tubulin', 'animal development -> generation', 'hydrogen atom -> change', 'small intestine -> buffer', 'pyrimidine -> RNA', 'renal medulla -> kidney', 'wing -> adaptation', 'pulse -> blastocyst', 'heat -> germinate', 'ruminant -> soil', 'bacteriophage -> bacterial infection', 'chromosome pair -> gamete', 'ciliate -> food plant', 'work -> multicellular organism', 'secondary endosymbiosis -> stramenopile', 'encode -> insect', 'thylakoid -> petal', 'receive -> tissue', 'tumor -> produce', 'flight -> drug', 'afferent arteriole -> nephron', 'parent -> inherit', 'production -> beetles', 'back -> medicine', 'plasma cell -> substance', 'extinction -> feature', 'ingest -> heterotroph', 'release -> physiology', 'mussel -> feeding', 'skeleton -> release', 'lactic acid -> oxygen', 'chordate -> epidermis', 'stress -> appearance', 'cold -> determine'], 'FP': ['amylase -> digestive enzyme', 'amylose -> starch', 'asexual reproduction -> reproduce', 'atmosphere -> part', 'breathing -> gas exchange', 'cell theory -> theory', 'response -> signal', 'coenzyme -> cofactor', 'cold -> condition', 'competitive inhibition -> inhibition', 'compound eye -> eye', 'cytoskeleton -> cell structure', 'dormancy -> condition', 'double fertilization -> plant fertilization', 'ear -> sensory organ', 'egg cell -> gamete', 'electrical signal -> signal', 'epithelial cell -> animal cell', 'experiment -> study', 'extinct vertebrate -> extinct species', 'fermentation -> anaerobic metabolism', 'fish -> vertebrate', 'fossil record -> information', 'freshwater biome -> biome', 'functional protein -> protein', 'gated channel -> channel protein', 'gel -> semisolid substance', 'activate -> gene regulation', 'gene regulation -> regulation', 'gene regulation -> regulate', 'genetic disorder -> disorder', 'genotype -> genome', 'gravity -> force', 'groundwater -> water', 'human behavior -> behavior', 'inactivate -> dephosphorylation', 'magnoliid -> angiosperm', 'meiosis -> cell division', 'mitosis -> divide', 'mussel -> bivalve', 'nucleosome -> chromatin', 'reproduce -> asexual reproduction', 'phage -> virus', 'phosphorylate -> phosphorylation', 'convert -> phosphorylation', 'phytochrome -> photoreceptor', 'pollination -> transfer', 'presynaptic cell -> nerve cell', 'bacterial gene -> gene', 'receptor protein -> receptor', 'transfer -> receive', 'RNA polymerase -> polymerase', 'sea star -> echinoderm', 'sensory neuron -> neuron', 'amplification -> signal', 'space -> part', 'species -> complex', 'study -> experiment', 'sunlight -> light energy', 'suspension feeding -> feeding', 'terrestrial plant -> plant', 'unsaturated fatty acid -> fatty acid', 'uracil -> pyrimidine', 'vacuole -> organelle', 'outermost shell -> electron shell']}, 'subclass-of': {'TP': ['chemical -> substance', 'metal atom -> atom', 'abscisic acid -> plant hormone', 'move -> transport', 'adaptive immunity -> respond', 'aldose -> aldehyde', 'gut -> digestive tract', 'animal cell membrane -> plasma membrane', 'antigen receptor -> receptor', 'apicomplexan -> alveolate', 'archosaur -> reptile', 'aromatic hydrocarbon -> hydrocarbon', 'AUG -> start codon', 'base -> chemical', 'biome -> region', 'cancer -> disease', 'carbohydrate -> organic molecule', 'carboxyl group -> functional group', 'carrier -> heterozygous', 'cartilage -> connective tissue', 'convert -> release', 'groove -> top', 'element -> chemical', 'chemotaxis -> response', 'chief cell -> secretory cell', 'chlorophyll a -> chlorophyll', 'coccus -> bacteria', 'colon cancer -> cancer', 'colorectal-cancer -> cancer', 'concentration gradient -> gradient', 'conifer -> gymnosperm', 'connective tissue -> tissue', 'control group -> experimental group', 'coral reef -> marine biome', 'cork cambium -> lateral meristem', 'deductive reasoning -> scientific method', 'desert -> ecosystem', 'diacylglycerol -> phospholipid', 'diapsid -> amniote', 'diatom -> protist', 'diffuse -> diffusion', 'deoxyribonucleic acid -> nucleic acid', 'signal -> communicate with', 'embryogenesis -> develop', 'embryonic tissue -> tissue', 'end -> region', 'endoskeleton -> skeleton', 'energy -> object', 'enhancer -> control element', 'euryhaline -> organism', 'exergonic reaction -> release', 'fibrous protein -> protein', 'free - energy -> energy', 'fructose -> hexose', 'gametophyte -> multicellular organism', 'glucocorticoid -> corticosteroid', 'glyoxysome -> peroxisome', 'herbivore -> heterotroph', 'hydrostatic skeleton -> skeleton', 'incus -> bone', 'insertion -> mutation', 'intermediate filament -> fibrous protein', 'kidney -> excretory organ', 'kinetic energy -> energy', 'lateral meristem -> meristem', 'lateral root -> root', 'layer -> part', 'leech -> annelid', 'lipid -> organic molecule', 'lizard -> Squamata', 'lycophyte -> vascular plant', 'lymphocyte -> white - blood - cell', 'lysosome -> organelle', 'maltose -> disaccharide', 'megaspore -> spore', 'membrane -> permeability', 'cell membrane -> permeability', 'Mercury -> metal atom', 'mesoderm -> germ layer', 'microspore -> spore', 'nucleic acid -> macromolecule', 'oil -> fat', 'omnivore -> heterotroph', 'optical isomer -> isomer', 'ova -> gamete', 'parthenogenesis -> asexual reproduction', 'passive transport -> diffusion', 'pea -> legume', 'peripheral protein -> membrane protein', 'phloem -> vascular tissue', 'phosphorylated-molecule -> molecule', 'physiology -> biology', 'pineal gland -> endocrine gland', 'cell-membrane -> membrane', 'macromolecule -> chemical', 'polysaccharide -> carbohydrate', 'pore -> region', 'prion -> protein', 'red light -> light', 'redox reaction -> convert', 'release -> move', 'salivary gland -> gland', 'sex hormone -> steroid hormone', 'silent mutation -> point mutation', 'simple fruit -> fruit', 'spinal cord -> nerve cord', 'table - sugar -> disaccharide', 'sulfide -> anion', 'surface protein -> protein', 'protein synthesis -> polymerization', 'thyroxine -> thyroid hormone', 'taproot -> root', 'tick -> arachnid', 'trait -> character', 'tropic hormone -> hormone', 'tuatara -> lepidosaur', 'urea substance -> substance', 'vasectomy -> contraception', 'venule -> vein', 'riboflavin -> vitamin B', 'niacin -> vitamin B', 'ion -> substance'], 'FP': ['reproduction -> sponges', 'acid -> surface', 'canal -> separate', 'soil -> epicotyl', 'chloroplast -> green - algae', 'carrier -> glucose', 'solution -> tip', 'climate -> information', 'root -> produce', 'fruit -> bread mold', 'transcription factor -> respond', 'mitotic spindle -> mitosis', 'sac -> egg', 'unit -> cell', 'catalyst -> nucleic acid', 'membrane -> cytoskeleton', 'organ -> negative - feedback', 'polar substance -> organ', 'ectoderm -> parasite', 'hydrostatic skeleton -> invertebrate', 'dominant -> monohybrid', 'life cycle -> meiosis', 'hormone -> disease', 'voltage -> ligand', 'substance -> chemical signal', 'hydroxyl group -> amino acid', 'prokaryote -> methane', 'normal -> haploid cell', 'fish -> dinosaur', 'endometrium -> fetus', 'transduction -> system', 'grow -> root system', 'inhibition -> ether', 'phylogenetic tree -> researcher', 'drug -> region', 'cell wall -> cell wall material', 'bean -> surface', 'complex -> individual', 'marine invertebrate -> plant', 'protein -> complement system', 'vascular plant -> coelom', 'dinoflagellate -> present', 'make -> phosphate group', 'atom -> argon', 'peptidoglycan -> ether', 'system -> chemiosmosis', 'gamete -> fragmentation', 'root system -> period', 'competitive inhibitor -> solution', 'via -> mitosis', 'pheromone -> nerve cell', 'central nervous system -> neural tube', 'air sac -> communicate with', 'prokaryote -> telomerase', 'seed -> pollen grain', 'sodium chloride -> ionic substance', 'inflammatory response -> waste', 'electrical signal -> sensory system', 'lake -> fauna', 'nuclei -> system', 'blood -> heart', 'kidney -> kidney - failure', 'dominant -> glucose', 'combine -> pollen', 'orgasm -> gland', 'hypertonic -> signal transduction', 'red algae -> secondary endosymbiosis', 'vitamin K -> synthesize', 'reptile -> excrete', 'tissue -> transcription factor', 'polyphyletic -> organism', 'signal -> open', 'environment -> dominant', 'diploid cell -> meiosis', 'generate -> production', 'transcription factor -> cytoplasmic determinant', 'disease -> membrane', 'mucin -> produce', 'molybdenum -> cobalt atom', 'pyrimidine -> end', 'chromosome -> parent cell', 'mollusk -> complex', 'death -> bean', 'cavity -> eustachian tube', 'electromagnetic spectrum -> human', 'genotype -> codominance', 'infant -> anterior end', 'branch -> leaves', 'base -> adventitious root']}}\n"
     ]
    }
   ],
   "source": [
    "rel_dict = dump_tp_fp(y_pred, y_test, [\"subclass-of\"], rel_dataset_test)\n",
    "print(rel_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 0.5295698924731183\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.09      0.15       185\n",
      "           1       0.52      0.97      0.67       187\n",
      "\n",
      "    accuracy                           0.53       372\n",
      "   macro avg       0.62      0.53      0.41       372\n",
      "weighted avg       0.62      0.53      0.42       372\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf = svm.SVC(gamma='scale')\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "print(\"Accuracy\", clf.score(X_test, y_test))\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 0.5698924731182796\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      0.48      0.53       185\n",
      "           1       0.56      0.66      0.61       187\n",
      "\n",
      "    accuracy                           0.57       372\n",
      "   macro avg       0.57      0.57      0.57       372\n",
      "weighted avg       0.57      0.57      0.57       372\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf = RandomForestClassifier(n_estimators=100, max_depth=20,random_state=0)\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "print(\"Accuracy\", clf.score(X_test, y_test))\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"../../data/relation_extraction\"\n",
    "rel_dataset_train = RelationDataset(data_dir=data_dir, split=\"train\", relations=[\"subclass-of\", 'has-part', 'possesses', 'has-region', 'is-inside', 'is-at', 'element', 'abuts', 'is-outside'], embedding_type=\"custom\", max_sent_length=256)\n",
    "rel_dataset_test = RelationDataset(data_dir=data_dir, split=\"test\", relations=[\"subclass-of\", 'has-part', 'possesses', 'has-region', 'is-inside', 'is-at', 'element', 'abuts', 'is-outside'], embedding_type=\"custom\", max_sent_length=256)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]),\n",
       " array([1912,  868,  602,   71,  162,  109,   32,   64,   18,   15]))"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id2vocab = json.load(open(os.path.join(\"../../data/relation_extraction\", 'id2word.json')))\n",
    "X_train, y_train = construct_minz_dataset(rel_dataset_train)\n",
    "X_test, y_test = construct_minz_dataset(rel_dataset_test)\n",
    "np.unique(y_train, return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 0.5448028673835126\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.79      0.68       415\n",
      "           1       0.39      0.30      0.34       187\n",
      "           2       0.56      0.41      0.47       130\n",
      "           3       0.50      0.31      0.38        16\n",
      "           4       0.50      0.22      0.31        36\n",
      "           5       0.44      0.17      0.24        24\n",
      "           6       0.00      0.00      0.00         7\n",
      "           7       0.00      0.00      0.00        14\n",
      "           8       0.50      0.25      0.33         4\n",
      "           9       0.00      0.00      0.00         4\n",
      "\n",
      "    accuracy                           0.54       837\n",
      "   macro avg       0.35      0.25      0.28       837\n",
      "weighted avg       0.51      0.54      0.51       837\n",
      "\n",
      "[[-8.86601350e-05  0.00000000e+00  5.78052339e-02 ...  0.00000000e+00\n",
      "   0.00000000e+00 -9.49881261e-03]\n",
      " [-2.69760862e-03  0.00000000e+00 -4.22132824e-02 ...  0.00000000e+00\n",
      "   0.00000000e+00 -8.04476174e-03]\n",
      " [-4.99736115e-03  0.00000000e+00 -9.28173307e-02 ...  0.00000000e+00\n",
      "   0.00000000e+00  1.38779523e-02]\n",
      " ...\n",
      " [-1.63639879e-02  0.00000000e+00 -5.54822161e-02 ...  0.00000000e+00\n",
      "   0.00000000e+00 -2.17516067e-03]\n",
      " [-1.43920832e-02  0.00000000e+00 -1.04835324e-01 ...  0.00000000e+00\n",
      "   0.00000000e+00 -2.17436030e-04]\n",
      " [-2.23760815e-02  0.00000000e+00 -6.98626355e-02 ...  0.00000000e+00\n",
      "   0.00000000e+00 -1.41616707e-03]]\n"
     ]
    }
   ],
   "source": [
    "clf = LogisticRegression(random_state=0, solver='lbfgs')\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "print(\"Accuracy\", clf.score(X_test, y_test))\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(clf.coef_) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 0.5137395459976105\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.52      0.98      0.68       415\n",
      "           1       0.40      0.01      0.02       187\n",
      "           2       0.48      0.15      0.23       130\n",
      "           3       0.00      0.00      0.00        16\n",
      "           4       0.00      0.00      0.00        36\n",
      "           5       0.25      0.04      0.07        24\n",
      "           6       0.00      0.00      0.00         7\n",
      "           7       0.00      0.00      0.00        14\n",
      "           8       0.00      0.00      0.00         4\n",
      "           9       0.00      0.00      0.00         4\n",
      "\n",
      "    accuracy                           0.51       837\n",
      "   macro avg       0.16      0.12      0.10       837\n",
      "weighted avg       0.43      0.51      0.38       837\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf = RandomForestClassifier(n_estimators=100, max_depth=20,random_state=0)\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "print(\"Accuracy\", clf.score(X_test, y_test))\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = svm.SVC(gamma='scale')\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "print(\"Accuracy\", clf.score(X_test, y_test))\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(y_test, return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rel_dict = dump_tp_fp(y_pred, y_test,[\"subclass-of\", 'has-part', 'possesses', 'has-region', 'is-inside', 'is-at', 'element', 'abuts', 'is-outside'], rel_dataset_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tokn",
   "language": "python",
   "name": "tokn"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
